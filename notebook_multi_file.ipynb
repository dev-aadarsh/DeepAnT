{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Training-on-A1-BenchMark-data\" data-toc-modified-id=\"Training-on-A1-BenchMark-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Training on A1 BenchMark data</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt                        \n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5\n",
    "YAHOO_FOLDER = 'ydata-labeled-time-series-anomalies-v1_0'\n",
    "SYNTHETIC_FOLDER = 'synthetic-labeled-data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on A1 BenchMark data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>is_anomaly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.265278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.100833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.147778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.053889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.051944</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2.680556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>3.063889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>2.462778</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>1.616667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>1.354722</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1461 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              value  is_anomaly\n",
       "timestamp                      \n",
       "1          1.265278           0\n",
       "2          1.100833           0\n",
       "3          1.147778           0\n",
       "4          1.053889           0\n",
       "5          1.051944           0\n",
       "...             ...         ...\n",
       "1457       2.680556           1\n",
       "1458       3.063889           1\n",
       "1459       2.462778           1\n",
       "1460       1.616667           0\n",
       "1461       1.354722           0\n",
       "\n",
       "[1461 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data = pd.read_csv(YAHOO_FOLDER + '/A1Benchmark/real_60.csv',index_col = 0)\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_anomaly</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            value\n",
       "is_anomaly       \n",
       "0            1445\n",
       "1              16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data[['is_anomaly','value']].groupby('is_anomaly').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percent = int(0.3*len(ts_data))\n",
    "valid_percent = int(0.1*len(ts_data))\n",
    "test_percent = int(0.6*len(ts_data))\n",
    "\n",
    "train_data = list(ts_data.iloc[:train_percent,0])\n",
    "valid_data = list(ts_data.iloc[train_percent:train_percent+valid_percent,0])\n",
    "test_data = list(ts_data.iloc[train_percent+valid_percent:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 45\n",
    "pred_window = 1\n",
    "filter1_size = 128\n",
    "filter2_size = 32\n",
    "kernel_size = 2\n",
    "stride = 1\n",
    "pool_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subsequences(data):\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for i in range(len(data) - w -pred_window):\n",
    "        X.append(data[i:i+w])\n",
    "        Y.append(data[i+w:i+w+pred_window])\n",
    "    return np.array(X),np.array(Y)\n",
    "\n",
    "trainX,trainY = get_subsequences(train_data)\n",
    "trainX = np.reshape(trainX,(trainX.shape[0],1,trainX.shape[1]))\n",
    "\n",
    "validX,validY = get_subsequences(valid_data)\n",
    "validX = np.reshape(validX,(validX.shape[0],1,validX.shape[1]))\n",
    "\n",
    "testX,testY = get_subsequences(test_data)\n",
    "testX = np.reshape(testX,(testX.shape[0],1,testX.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        ## layers of a CNN\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(1,filter1_size,kernel_size,stride,padding = 0)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(filter1_size,filter2_size,kernel_size,stride,padding = 0)\n",
    "\n",
    "        self.maxpool = nn.MaxPool1d(pool_size)\n",
    "        \n",
    "        self.dim1 = int(0.5*(0.5*(w-1)-1)) * filter2_size\n",
    "        \n",
    "        self.lin1 = nn.Linear(self.dim1,pred_window )\n",
    "        #self.lin2 = nn.Linear(1000,pred_window)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #convolution layer 1\n",
    "        x = (F.relu(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        #print(x.shape)\n",
    "        #x = self.dropout(x)\n",
    "\n",
    "\n",
    "             \n",
    "        #convolution layer 2\n",
    "        x = (F.relu(self.conv2(x)))\n",
    "        x = self.maxpool(x)\n",
    "        #x = self.dropout(x)\n",
    "\n",
    "        #print(x.shape)\n",
    "\n",
    "\n",
    "        #print(x.shape)\n",
    "        #print(int(0.25* (w) * filter2_size))\n",
    "        x = x.view(-1,self.dim1)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.lin1(x)\n",
    "        #x = self.dropout(x)\n",
    "        #x = self.lin2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv1d(1, 128, kernel_size=(2,), stride=(1,))\n",
      "  (conv2): Conv1d(128, 32, kernel_size=(2,), stride=(1,))\n",
      "  (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (lin1): Linear(in_features=320, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_A1 = Net()\n",
    "print(model_A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_scratch = nn.L1Loss()\n",
    "optimizer_scratch = optim.Adam(model_A1.parameters(), lr = 1e-5,weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid(n_epochs, trainX,trainY, validX,validY,model, optimizer, criterion,save_path,freq = 20):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "\n",
    "    target_train = torch.tensor(trainY).type('torch.FloatTensor')\n",
    "    data_train = torch.tensor(trainX).type('torch.FloatTensor')\n",
    "    \n",
    "    target_valid = torch.tensor(validY).type('torch.FloatTensor')\n",
    "    data_valid = torch.tensor(validX).type('torch.FloatTensor')\n",
    "    \n",
    "    train_loss_min = np.Inf\n",
    "    valid_loss_min = np.Inf\n",
    "    last_valid_loss= 0\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        \n",
    "        ###################\n",
    "        # training the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "\n",
    "        #print(data.shape)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data_train)\n",
    "        loss = criterion(output, target_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss = loss.item()\n",
    "        \n",
    "        ###################\n",
    "        # Validation #\n",
    "        ###################\n",
    "        model.eval()\n",
    "        output_valid = model(data_valid)\n",
    "        \n",
    "        loss_valid = criterion(output_valid, target_valid)\n",
    "        valid_loss = loss_valid.item()\n",
    "        if(valid_loss == last_valid_loss):\n",
    "            print('problem')\n",
    "            \n",
    "        last_valid_loss = valid_loss\n",
    "        if(epoch%freq == 0):\n",
    "            print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "                epoch, \n",
    "                train_loss,\n",
    "                valid_loss\n",
    "                ))\n",
    "            \n",
    "        if valid_loss < valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    return model,output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.975113).  Saving model ...\n",
      "Validation loss decreased (0.975113 --> 0.973752).  Saving model ...\n",
      "Validation loss decreased (0.973752 --> 0.972388).  Saving model ...\n",
      "Validation loss decreased (0.972388 --> 0.971019).  Saving model ...\n",
      "Validation loss decreased (0.971019 --> 0.969651).  Saving model ...\n",
      "Validation loss decreased (0.969651 --> 0.968277).  Saving model ...\n",
      "Validation loss decreased (0.968277 --> 0.966903).  Saving model ...\n",
      "Validation loss decreased (0.966903 --> 0.965530).  Saving model ...\n",
      "Validation loss decreased (0.965530 --> 0.964157).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.018247 \tValidation Loss: 0.962784\n",
      "Validation loss decreased (0.964157 --> 0.962784).  Saving model ...\n",
      "Validation loss decreased (0.962784 --> 0.961411).  Saving model ...\n",
      "Validation loss decreased (0.961411 --> 0.960035).  Saving model ...\n",
      "Validation loss decreased (0.960035 --> 0.958654).  Saving model ...\n",
      "Validation loss decreased (0.958654 --> 0.957273).  Saving model ...\n",
      "Validation loss decreased (0.957273 --> 0.955891).  Saving model ...\n",
      "Validation loss decreased (0.955891 --> 0.954509).  Saving model ...\n",
      "Validation loss decreased (0.954509 --> 0.953123).  Saving model ...\n",
      "Validation loss decreased (0.953123 --> 0.951734).  Saving model ...\n",
      "Validation loss decreased (0.951734 --> 0.950342).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 1.004268 \tValidation Loss: 0.948947\n",
      "Validation loss decreased (0.950342 --> 0.948947).  Saving model ...\n",
      "Validation loss decreased (0.948947 --> 0.947553).  Saving model ...\n",
      "Validation loss decreased (0.947553 --> 0.946158).  Saving model ...\n",
      "Validation loss decreased (0.946158 --> 0.944765).  Saving model ...\n",
      "Validation loss decreased (0.944765 --> 0.943373).  Saving model ...\n",
      "Validation loss decreased (0.943373 --> 0.941981).  Saving model ...\n",
      "Validation loss decreased (0.941981 --> 0.940591).  Saving model ...\n",
      "Validation loss decreased (0.940591 --> 0.939204).  Saving model ...\n",
      "Validation loss decreased (0.939204 --> 0.937818).  Saving model ...\n",
      "Validation loss decreased (0.937818 --> 0.936431).  Saving model ...\n",
      "Epoch: 30 \tTraining Loss: 0.990099 \tValidation Loss: 0.935047\n",
      "Validation loss decreased (0.936431 --> 0.935047).  Saving model ...\n",
      "Validation loss decreased (0.935047 --> 0.933661).  Saving model ...\n",
      "Validation loss decreased (0.933661 --> 0.932277).  Saving model ...\n",
      "Validation loss decreased (0.932277 --> 0.930894).  Saving model ...\n",
      "Validation loss decreased (0.930894 --> 0.929509).  Saving model ...\n",
      "Validation loss decreased (0.929509 --> 0.928119).  Saving model ...\n",
      "Validation loss decreased (0.928119 --> 0.926730).  Saving model ...\n",
      "Validation loss decreased (0.926730 --> 0.925341).  Saving model ...\n",
      "Validation loss decreased (0.925341 --> 0.923953).  Saving model ...\n",
      "Validation loss decreased (0.923953 --> 0.922567).  Saving model ...\n",
      "Epoch: 40 \tTraining Loss: 0.972575 \tValidation Loss: 0.921180\n",
      "Validation loss decreased (0.922567 --> 0.921180).  Saving model ...\n",
      "Validation loss decreased (0.921180 --> 0.919791).  Saving model ...\n",
      "Validation loss decreased (0.919791 --> 0.918405).  Saving model ...\n",
      "Validation loss decreased (0.918405 --> 0.917020).  Saving model ...\n",
      "Validation loss decreased (0.917020 --> 0.915639).  Saving model ...\n",
      "Validation loss decreased (0.915639 --> 0.914255).  Saving model ...\n",
      "Validation loss decreased (0.914255 --> 0.912869).  Saving model ...\n",
      "Validation loss decreased (0.912869 --> 0.911484).  Saving model ...\n",
      "Validation loss decreased (0.911484 --> 0.910099).  Saving model ...\n",
      "Validation loss decreased (0.910099 --> 0.908716).  Saving model ...\n",
      "Epoch: 50 \tTraining Loss: 0.967285 \tValidation Loss: 0.907333\n",
      "Validation loss decreased (0.908716 --> 0.907333).  Saving model ...\n",
      "Validation loss decreased (0.907333 --> 0.905951).  Saving model ...\n",
      "Validation loss decreased (0.905951 --> 0.904569).  Saving model ...\n",
      "Validation loss decreased (0.904569 --> 0.903187).  Saving model ...\n",
      "Validation loss decreased (0.903187 --> 0.901803).  Saving model ...\n",
      "Validation loss decreased (0.901803 --> 0.900419).  Saving model ...\n",
      "Validation loss decreased (0.900419 --> 0.899037).  Saving model ...\n",
      "Validation loss decreased (0.899037 --> 0.897654).  Saving model ...\n",
      "Validation loss decreased (0.897654 --> 0.896272).  Saving model ...\n",
      "Validation loss decreased (0.896272 --> 0.894887).  Saving model ...\n",
      "Epoch: 60 \tTraining Loss: 0.946914 \tValidation Loss: 0.893502\n",
      "Validation loss decreased (0.894887 --> 0.893502).  Saving model ...\n",
      "Validation loss decreased (0.893502 --> 0.892116).  Saving model ...\n",
      "Validation loss decreased (0.892116 --> 0.890730).  Saving model ...\n",
      "Validation loss decreased (0.890730 --> 0.889345).  Saving model ...\n",
      "Validation loss decreased (0.889345 --> 0.887962).  Saving model ...\n",
      "Validation loss decreased (0.887962 --> 0.886579).  Saving model ...\n",
      "Validation loss decreased (0.886579 --> 0.885196).  Saving model ...\n",
      "Validation loss decreased (0.885196 --> 0.883813).  Saving model ...\n",
      "Validation loss decreased (0.883813 --> 0.882432).  Saving model ...\n",
      "Validation loss decreased (0.882432 --> 0.881052).  Saving model ...\n",
      "Epoch: 70 \tTraining Loss: 0.939097 \tValidation Loss: 0.879672\n",
      "Validation loss decreased (0.881052 --> 0.879672).  Saving model ...\n",
      "Validation loss decreased (0.879672 --> 0.878292).  Saving model ...\n",
      "Validation loss decreased (0.878292 --> 0.876914).  Saving model ...\n",
      "Validation loss decreased (0.876914 --> 0.875538).  Saving model ...\n",
      "Validation loss decreased (0.875538 --> 0.874164).  Saving model ...\n",
      "Validation loss decreased (0.874164 --> 0.872789).  Saving model ...\n",
      "Validation loss decreased (0.872789 --> 0.871411).  Saving model ...\n",
      "Validation loss decreased (0.871411 --> 0.870032).  Saving model ...\n",
      "Validation loss decreased (0.870032 --> 0.868654).  Saving model ...\n",
      "Validation loss decreased (0.868654 --> 0.867276).  Saving model ...\n",
      "Epoch: 80 \tTraining Loss: 0.919509 \tValidation Loss: 0.865899\n",
      "Validation loss decreased (0.867276 --> 0.865899).  Saving model ...\n",
      "Validation loss decreased (0.865899 --> 0.864521).  Saving model ...\n",
      "Validation loss decreased (0.864521 --> 0.863144).  Saving model ...\n",
      "Validation loss decreased (0.863144 --> 0.861770).  Saving model ...\n",
      "Validation loss decreased (0.861770 --> 0.860395).  Saving model ...\n",
      "Validation loss decreased (0.860395 --> 0.859021).  Saving model ...\n",
      "Validation loss decreased (0.859021 --> 0.857646).  Saving model ...\n",
      "Validation loss decreased (0.857646 --> 0.856270).  Saving model ...\n",
      "Validation loss decreased (0.856270 --> 0.854892).  Saving model ...\n",
      "Validation loss decreased (0.854892 --> 0.853514).  Saving model ...\n",
      "Epoch: 90 \tTraining Loss: 0.910985 \tValidation Loss: 0.852135\n",
      "Validation loss decreased (0.853514 --> 0.852135).  Saving model ...\n",
      "Validation loss decreased (0.852135 --> 0.850756).  Saving model ...\n",
      "Validation loss decreased (0.850756 --> 0.849377).  Saving model ...\n",
      "Validation loss decreased (0.849377 --> 0.847997).  Saving model ...\n",
      "Validation loss decreased (0.847997 --> 0.846617).  Saving model ...\n",
      "Validation loss decreased (0.846617 --> 0.845238).  Saving model ...\n",
      "Validation loss decreased (0.845238 --> 0.843858).  Saving model ...\n",
      "Validation loss decreased (0.843858 --> 0.842478).  Saving model ...\n",
      "Validation loss decreased (0.842478 --> 0.841097).  Saving model ...\n",
      "Validation loss decreased (0.841097 --> 0.839716).  Saving model ...\n",
      "Epoch: 100 \tTraining Loss: 0.901232 \tValidation Loss: 0.838336\n",
      "Validation loss decreased (0.839716 --> 0.838336).  Saving model ...\n",
      "Validation loss decreased (0.838336 --> 0.836954).  Saving model ...\n",
      "Validation loss decreased (0.836954 --> 0.835570).  Saving model ...\n",
      "Validation loss decreased (0.835570 --> 0.834187).  Saving model ...\n",
      "Validation loss decreased (0.834187 --> 0.832802).  Saving model ...\n",
      "Validation loss decreased (0.832802 --> 0.831416).  Saving model ...\n",
      "Validation loss decreased (0.831416 --> 0.830028).  Saving model ...\n",
      "Validation loss decreased (0.830028 --> 0.828638).  Saving model ...\n",
      "Validation loss decreased (0.828638 --> 0.827248).  Saving model ...\n",
      "Validation loss decreased (0.827248 --> 0.825856).  Saving model ...\n",
      "Epoch: 110 \tTraining Loss: 0.886793 \tValidation Loss: 0.824463\n",
      "Validation loss decreased (0.825856 --> 0.824463).  Saving model ...\n",
      "Validation loss decreased (0.824463 --> 0.823072).  Saving model ...\n",
      "Validation loss decreased (0.823072 --> 0.821682).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.821682 --> 0.820290).  Saving model ...\n",
      "Validation loss decreased (0.820290 --> 0.818893).  Saving model ...\n",
      "Validation loss decreased (0.818893 --> 0.817496).  Saving model ...\n",
      "Validation loss decreased (0.817496 --> 0.816098).  Saving model ...\n",
      "Validation loss decreased (0.816098 --> 0.814702).  Saving model ...\n",
      "Validation loss decreased (0.814702 --> 0.813304).  Saving model ...\n",
      "Validation loss decreased (0.813304 --> 0.811907).  Saving model ...\n",
      "Epoch: 120 \tTraining Loss: 0.875461 \tValidation Loss: 0.810508\n",
      "Validation loss decreased (0.811907 --> 0.810508).  Saving model ...\n",
      "Validation loss decreased (0.810508 --> 0.809108).  Saving model ...\n",
      "Validation loss decreased (0.809108 --> 0.807707).  Saving model ...\n",
      "Validation loss decreased (0.807707 --> 0.806302).  Saving model ...\n",
      "Validation loss decreased (0.806302 --> 0.804895).  Saving model ...\n",
      "Validation loss decreased (0.804895 --> 0.803488).  Saving model ...\n",
      "Validation loss decreased (0.803488 --> 0.802080).  Saving model ...\n",
      "Validation loss decreased (0.802080 --> 0.800668).  Saving model ...\n",
      "Validation loss decreased (0.800668 --> 0.799255).  Saving model ...\n",
      "Validation loss decreased (0.799255 --> 0.797843).  Saving model ...\n",
      "Epoch: 130 \tTraining Loss: 0.857738 \tValidation Loss: 0.796427\n",
      "Validation loss decreased (0.797843 --> 0.796427).  Saving model ...\n",
      "Validation loss decreased (0.796427 --> 0.795013).  Saving model ...\n",
      "Validation loss decreased (0.795013 --> 0.793595).  Saving model ...\n",
      "Validation loss decreased (0.793595 --> 0.792177).  Saving model ...\n",
      "Validation loss decreased (0.792177 --> 0.790757).  Saving model ...\n",
      "Validation loss decreased (0.790757 --> 0.789336).  Saving model ...\n",
      "Validation loss decreased (0.789336 --> 0.787915).  Saving model ...\n",
      "Validation loss decreased (0.787915 --> 0.786493).  Saving model ...\n",
      "Validation loss decreased (0.786493 --> 0.785070).  Saving model ...\n",
      "Validation loss decreased (0.785070 --> 0.783645).  Saving model ...\n",
      "Epoch: 140 \tTraining Loss: 0.848038 \tValidation Loss: 0.782218\n",
      "Validation loss decreased (0.783645 --> 0.782218).  Saving model ...\n",
      "Validation loss decreased (0.782218 --> 0.780788).  Saving model ...\n",
      "Validation loss decreased (0.780788 --> 0.779356).  Saving model ...\n",
      "Validation loss decreased (0.779356 --> 0.777924).  Saving model ...\n",
      "Validation loss decreased (0.777924 --> 0.776490).  Saving model ...\n",
      "Validation loss decreased (0.776490 --> 0.775054).  Saving model ...\n",
      "Validation loss decreased (0.775054 --> 0.773613).  Saving model ...\n",
      "Validation loss decreased (0.773613 --> 0.772175).  Saving model ...\n",
      "Validation loss decreased (0.772175 --> 0.770732).  Saving model ...\n",
      "Validation loss decreased (0.770732 --> 0.769287).  Saving model ...\n",
      "Epoch: 150 \tTraining Loss: 0.837353 \tValidation Loss: 0.767842\n",
      "Validation loss decreased (0.769287 --> 0.767842).  Saving model ...\n",
      "Validation loss decreased (0.767842 --> 0.766395).  Saving model ...\n",
      "Validation loss decreased (0.766395 --> 0.764946).  Saving model ...\n",
      "Validation loss decreased (0.764946 --> 0.763496).  Saving model ...\n",
      "Validation loss decreased (0.763496 --> 0.762045).  Saving model ...\n",
      "Validation loss decreased (0.762045 --> 0.760591).  Saving model ...\n",
      "Validation loss decreased (0.760591 --> 0.759134).  Saving model ...\n",
      "Validation loss decreased (0.759134 --> 0.757676).  Saving model ...\n",
      "Validation loss decreased (0.757676 --> 0.756216).  Saving model ...\n",
      "Validation loss decreased (0.756216 --> 0.754754).  Saving model ...\n",
      "Epoch: 160 \tTraining Loss: 0.823366 \tValidation Loss: 0.753293\n",
      "Validation loss decreased (0.754754 --> 0.753293).  Saving model ...\n",
      "Validation loss decreased (0.753293 --> 0.751830).  Saving model ...\n",
      "Validation loss decreased (0.751830 --> 0.750362).  Saving model ...\n",
      "Validation loss decreased (0.750362 --> 0.748894).  Saving model ...\n",
      "Validation loss decreased (0.748894 --> 0.747425).  Saving model ...\n",
      "Validation loss decreased (0.747425 --> 0.745953).  Saving model ...\n",
      "Validation loss decreased (0.745953 --> 0.744481).  Saving model ...\n",
      "Validation loss decreased (0.744481 --> 0.743006).  Saving model ...\n",
      "Validation loss decreased (0.743006 --> 0.741530).  Saving model ...\n",
      "Validation loss decreased (0.741530 --> 0.740052).  Saving model ...\n",
      "Epoch: 170 \tTraining Loss: 0.807454 \tValidation Loss: 0.738572\n",
      "Validation loss decreased (0.740052 --> 0.738572).  Saving model ...\n",
      "Validation loss decreased (0.738572 --> 0.737087).  Saving model ...\n",
      "Validation loss decreased (0.737087 --> 0.735601).  Saving model ...\n",
      "Validation loss decreased (0.735601 --> 0.734112).  Saving model ...\n",
      "Validation loss decreased (0.734112 --> 0.732623).  Saving model ...\n",
      "Validation loss decreased (0.732623 --> 0.731131).  Saving model ...\n",
      "Validation loss decreased (0.731131 --> 0.729636).  Saving model ...\n",
      "Validation loss decreased (0.729636 --> 0.728138).  Saving model ...\n",
      "Validation loss decreased (0.728138 --> 0.726636).  Saving model ...\n",
      "Validation loss decreased (0.726636 --> 0.725132).  Saving model ...\n",
      "Epoch: 180 \tTraining Loss: 0.786013 \tValidation Loss: 0.723627\n",
      "Validation loss decreased (0.725132 --> 0.723627).  Saving model ...\n",
      "Validation loss decreased (0.723627 --> 0.722118).  Saving model ...\n",
      "Validation loss decreased (0.722118 --> 0.720606).  Saving model ...\n",
      "Validation loss decreased (0.720606 --> 0.719092).  Saving model ...\n",
      "Validation loss decreased (0.719092 --> 0.717576).  Saving model ...\n",
      "Validation loss decreased (0.717576 --> 0.716058).  Saving model ...\n",
      "Validation loss decreased (0.716058 --> 0.714536).  Saving model ...\n",
      "Validation loss decreased (0.714536 --> 0.713013).  Saving model ...\n",
      "Validation loss decreased (0.713013 --> 0.711489).  Saving model ...\n",
      "Validation loss decreased (0.711489 --> 0.709964).  Saving model ...\n",
      "Epoch: 190 \tTraining Loss: 0.770679 \tValidation Loss: 0.708436\n",
      "Validation loss decreased (0.709964 --> 0.708436).  Saving model ...\n",
      "Validation loss decreased (0.708436 --> 0.706910).  Saving model ...\n",
      "Validation loss decreased (0.706910 --> 0.705381).  Saving model ...\n",
      "Validation loss decreased (0.705381 --> 0.703850).  Saving model ...\n",
      "Validation loss decreased (0.703850 --> 0.702318).  Saving model ...\n",
      "Validation loss decreased (0.702318 --> 0.700786).  Saving model ...\n",
      "Validation loss decreased (0.700786 --> 0.699252).  Saving model ...\n",
      "Validation loss decreased (0.699252 --> 0.697714).  Saving model ...\n",
      "Validation loss decreased (0.697714 --> 0.696174).  Saving model ...\n",
      "Validation loss decreased (0.696174 --> 0.694632).  Saving model ...\n",
      "Epoch: 200 \tTraining Loss: 0.757824 \tValidation Loss: 0.693087\n",
      "Validation loss decreased (0.694632 --> 0.693087).  Saving model ...\n",
      "Validation loss decreased (0.693087 --> 0.691540).  Saving model ...\n",
      "Validation loss decreased (0.691540 --> 0.689992).  Saving model ...\n",
      "Validation loss decreased (0.689992 --> 0.688441).  Saving model ...\n",
      "Validation loss decreased (0.688441 --> 0.686890).  Saving model ...\n",
      "Validation loss decreased (0.686890 --> 0.685340).  Saving model ...\n",
      "Validation loss decreased (0.685340 --> 0.683789).  Saving model ...\n",
      "Validation loss decreased (0.683789 --> 0.682235).  Saving model ...\n",
      "Validation loss decreased (0.682235 --> 0.680678).  Saving model ...\n",
      "Validation loss decreased (0.680678 --> 0.679117).  Saving model ...\n",
      "Epoch: 210 \tTraining Loss: 0.760782 \tValidation Loss: 0.677555\n",
      "Validation loss decreased (0.679117 --> 0.677555).  Saving model ...\n",
      "Validation loss decreased (0.677555 --> 0.675990).  Saving model ...\n",
      "Validation loss decreased (0.675990 --> 0.674425).  Saving model ...\n",
      "Validation loss decreased (0.674425 --> 0.672859).  Saving model ...\n",
      "Validation loss decreased (0.672859 --> 0.671290).  Saving model ...\n",
      "Validation loss decreased (0.671290 --> 0.669717).  Saving model ...\n",
      "Validation loss decreased (0.669717 --> 0.668144).  Saving model ...\n",
      "Validation loss decreased (0.668144 --> 0.666570).  Saving model ...\n",
      "Validation loss decreased (0.666570 --> 0.664993).  Saving model ...\n",
      "Validation loss decreased (0.664993 --> 0.663411).  Saving model ...\n",
      "Epoch: 220 \tTraining Loss: 0.736155 \tValidation Loss: 0.661827\n",
      "Validation loss decreased (0.663411 --> 0.661827).  Saving model ...\n",
      "Validation loss decreased (0.661827 --> 0.660241).  Saving model ...\n",
      "Validation loss decreased (0.660241 --> 0.658650).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.658650 --> 0.657055).  Saving model ...\n",
      "Validation loss decreased (0.657055 --> 0.655456).  Saving model ...\n",
      "Validation loss decreased (0.655456 --> 0.653854).  Saving model ...\n",
      "Validation loss decreased (0.653854 --> 0.652249).  Saving model ...\n",
      "Validation loss decreased (0.652249 --> 0.650640).  Saving model ...\n",
      "Validation loss decreased (0.650640 --> 0.649027).  Saving model ...\n",
      "Validation loss decreased (0.649027 --> 0.647410).  Saving model ...\n",
      "Epoch: 230 \tTraining Loss: 0.716848 \tValidation Loss: 0.645790\n",
      "Validation loss decreased (0.647410 --> 0.645790).  Saving model ...\n",
      "Validation loss decreased (0.645790 --> 0.644166).  Saving model ...\n",
      "Validation loss decreased (0.644166 --> 0.642543).  Saving model ...\n",
      "Validation loss decreased (0.642543 --> 0.640915).  Saving model ...\n",
      "Validation loss decreased (0.640915 --> 0.639282).  Saving model ...\n",
      "Validation loss decreased (0.639282 --> 0.637645).  Saving model ...\n",
      "Validation loss decreased (0.637645 --> 0.636007).  Saving model ...\n",
      "Validation loss decreased (0.636007 --> 0.634367).  Saving model ...\n",
      "Validation loss decreased (0.634367 --> 0.632725).  Saving model ...\n",
      "Validation loss decreased (0.632725 --> 0.631078).  Saving model ...\n",
      "Epoch: 240 \tTraining Loss: 0.695714 \tValidation Loss: 0.629425\n",
      "Validation loss decreased (0.631078 --> 0.629425).  Saving model ...\n",
      "Validation loss decreased (0.629425 --> 0.627768).  Saving model ...\n",
      "Validation loss decreased (0.627768 --> 0.626109).  Saving model ...\n",
      "Validation loss decreased (0.626109 --> 0.624446).  Saving model ...\n",
      "Validation loss decreased (0.624446 --> 0.622791).  Saving model ...\n",
      "Validation loss decreased (0.622791 --> 0.621176).  Saving model ...\n",
      "Validation loss decreased (0.621176 --> 0.619560).  Saving model ...\n",
      "Validation loss decreased (0.619560 --> 0.617939).  Saving model ...\n",
      "Validation loss decreased (0.617939 --> 0.616324).  Saving model ...\n",
      "Validation loss decreased (0.616324 --> 0.614755).  Saving model ...\n",
      "Epoch: 250 \tTraining Loss: 0.690410 \tValidation Loss: 0.613184\n",
      "Validation loss decreased (0.614755 --> 0.613184).  Saving model ...\n",
      "Validation loss decreased (0.613184 --> 0.611612).  Saving model ...\n",
      "Validation loss decreased (0.611612 --> 0.610034).  Saving model ...\n",
      "Validation loss decreased (0.610034 --> 0.608454).  Saving model ...\n",
      "Validation loss decreased (0.608454 --> 0.606872).  Saving model ...\n",
      "Validation loss decreased (0.606872 --> 0.605286).  Saving model ...\n",
      "Validation loss decreased (0.605286 --> 0.603700).  Saving model ...\n",
      "Validation loss decreased (0.603700 --> 0.602110).  Saving model ...\n",
      "Validation loss decreased (0.602110 --> 0.600517).  Saving model ...\n",
      "Validation loss decreased (0.600517 --> 0.598921).  Saving model ...\n",
      "Epoch: 260 \tTraining Loss: 0.672772 \tValidation Loss: 0.597323\n",
      "Validation loss decreased (0.598921 --> 0.597323).  Saving model ...\n",
      "Validation loss decreased (0.597323 --> 0.595722).  Saving model ...\n",
      "Validation loss decreased (0.595722 --> 0.594117).  Saving model ...\n",
      "Validation loss decreased (0.594117 --> 0.592507).  Saving model ...\n",
      "Validation loss decreased (0.592507 --> 0.590893).  Saving model ...\n",
      "Validation loss decreased (0.590893 --> 0.589277).  Saving model ...\n",
      "Validation loss decreased (0.589277 --> 0.587658).  Saving model ...\n",
      "Validation loss decreased (0.587658 --> 0.586033).  Saving model ...\n",
      "Validation loss decreased (0.586033 --> 0.584405).  Saving model ...\n",
      "Validation loss decreased (0.584405 --> 0.582774).  Saving model ...\n",
      "Epoch: 270 \tTraining Loss: 0.653751 \tValidation Loss: 0.581138\n",
      "Validation loss decreased (0.582774 --> 0.581138).  Saving model ...\n",
      "Validation loss decreased (0.581138 --> 0.579502).  Saving model ...\n",
      "Validation loss decreased (0.579502 --> 0.577862).  Saving model ...\n",
      "Validation loss decreased (0.577862 --> 0.576225).  Saving model ...\n",
      "Validation loss decreased (0.576225 --> 0.574645).  Saving model ...\n",
      "Validation loss decreased (0.574645 --> 0.573062).  Saving model ...\n",
      "Validation loss decreased (0.573062 --> 0.571477).  Saving model ...\n",
      "Validation loss decreased (0.571477 --> 0.569889).  Saving model ...\n",
      "Validation loss decreased (0.569889 --> 0.568299).  Saving model ...\n",
      "Validation loss decreased (0.568299 --> 0.566705).  Saving model ...\n",
      "Epoch: 280 \tTraining Loss: 0.644373 \tValidation Loss: 0.565109\n",
      "Validation loss decreased (0.566705 --> 0.565109).  Saving model ...\n",
      "Validation loss decreased (0.565109 --> 0.563507).  Saving model ...\n",
      "Validation loss decreased (0.563507 --> 0.561899).  Saving model ...\n",
      "Validation loss decreased (0.561899 --> 0.560289).  Saving model ...\n",
      "Validation loss decreased (0.560289 --> 0.558676).  Saving model ...\n",
      "Validation loss decreased (0.558676 --> 0.557059).  Saving model ...\n",
      "Validation loss decreased (0.557059 --> 0.555441).  Saving model ...\n",
      "Validation loss decreased (0.555441 --> 0.553821).  Saving model ...\n",
      "Validation loss decreased (0.553821 --> 0.552198).  Saving model ...\n",
      "Validation loss decreased (0.552198 --> 0.550571).  Saving model ...\n",
      "Epoch: 290 \tTraining Loss: 0.630588 \tValidation Loss: 0.548943\n",
      "Validation loss decreased (0.550571 --> 0.548943).  Saving model ...\n",
      "Validation loss decreased (0.548943 --> 0.547309).  Saving model ...\n",
      "Validation loss decreased (0.547309 --> 0.545671).  Saving model ...\n",
      "Validation loss decreased (0.545671 --> 0.544029).  Saving model ...\n",
      "Validation loss decreased (0.544029 --> 0.542383).  Saving model ...\n",
      "Validation loss decreased (0.542383 --> 0.540732).  Saving model ...\n",
      "Validation loss decreased (0.540732 --> 0.539078).  Saving model ...\n",
      "Validation loss decreased (0.539078 --> 0.537422).  Saving model ...\n",
      "Validation loss decreased (0.537422 --> 0.535763).  Saving model ...\n",
      "Validation loss decreased (0.535763 --> 0.534102).  Saving model ...\n",
      "Epoch: 300 \tTraining Loss: 0.598772 \tValidation Loss: 0.532438\n",
      "Validation loss decreased (0.534102 --> 0.532438).  Saving model ...\n",
      "Validation loss decreased (0.532438 --> 0.530771).  Saving model ...\n",
      "Validation loss decreased (0.530771 --> 0.529102).  Saving model ...\n",
      "Validation loss decreased (0.529102 --> 0.527489).  Saving model ...\n",
      "Validation loss decreased (0.527489 --> 0.525876).  Saving model ...\n",
      "Validation loss decreased (0.525876 --> 0.524259).  Saving model ...\n",
      "Validation loss decreased (0.524259 --> 0.522640).  Saving model ...\n",
      "Validation loss decreased (0.522640 --> 0.521018).  Saving model ...\n",
      "Validation loss decreased (0.521018 --> 0.519393).  Saving model ...\n",
      "Validation loss decreased (0.519393 --> 0.517781).  Saving model ...\n",
      "Epoch: 310 \tTraining Loss: 0.584643 \tValidation Loss: 0.516201\n",
      "Validation loss decreased (0.517781 --> 0.516201).  Saving model ...\n",
      "Validation loss decreased (0.516201 --> 0.514620).  Saving model ...\n",
      "Validation loss decreased (0.514620 --> 0.513034).  Saving model ...\n",
      "Validation loss decreased (0.513034 --> 0.511446).  Saving model ...\n",
      "Validation loss decreased (0.511446 --> 0.509855).  Saving model ...\n",
      "Validation loss decreased (0.509855 --> 0.508262).  Saving model ...\n",
      "Validation loss decreased (0.508262 --> 0.506666).  Saving model ...\n",
      "Validation loss decreased (0.506666 --> 0.505065).  Saving model ...\n",
      "Validation loss decreased (0.505065 --> 0.503462).  Saving model ...\n",
      "Validation loss decreased (0.503462 --> 0.501857).  Saving model ...\n",
      "Epoch: 320 \tTraining Loss: 0.569636 \tValidation Loss: 0.500249\n",
      "Validation loss decreased (0.501857 --> 0.500249).  Saving model ...\n",
      "Validation loss decreased (0.500249 --> 0.498640).  Saving model ...\n",
      "Validation loss decreased (0.498640 --> 0.497028).  Saving model ...\n",
      "Validation loss decreased (0.497028 --> 0.495414).  Saving model ...\n",
      "Validation loss decreased (0.495414 --> 0.493797).  Saving model ...\n",
      "Validation loss decreased (0.493797 --> 0.492176).  Saving model ...\n",
      "Validation loss decreased (0.492176 --> 0.490551).  Saving model ...\n",
      "Validation loss decreased (0.490551 --> 0.488923).  Saving model ...\n",
      "Validation loss decreased (0.488923 --> 0.487296).  Saving model ...\n",
      "Validation loss decreased (0.487296 --> 0.485663).  Saving model ...\n",
      "Epoch: 330 \tTraining Loss: 0.558647 \tValidation Loss: 0.484030\n",
      "Validation loss decreased (0.485663 --> 0.484030).  Saving model ...\n",
      "Validation loss decreased (0.484030 --> 0.482394).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.482394 --> 0.480812).  Saving model ...\n",
      "Validation loss decreased (0.480812 --> 0.479232).  Saving model ...\n",
      "Validation loss decreased (0.479232 --> 0.477654).  Saving model ...\n",
      "Validation loss decreased (0.477654 --> 0.476078).  Saving model ...\n",
      "Validation loss decreased (0.476078 --> 0.474502).  Saving model ...\n",
      "Validation loss decreased (0.474502 --> 0.472925).  Saving model ...\n",
      "Validation loss decreased (0.472925 --> 0.471350).  Saving model ...\n",
      "Validation loss decreased (0.471350 --> 0.469775).  Saving model ...\n",
      "Epoch: 340 \tTraining Loss: 0.537766 \tValidation Loss: 0.468199\n",
      "Validation loss decreased (0.469775 --> 0.468199).  Saving model ...\n",
      "Validation loss decreased (0.468199 --> 0.466625).  Saving model ...\n",
      "Validation loss decreased (0.466625 --> 0.465051).  Saving model ...\n",
      "Validation loss decreased (0.465051 --> 0.463481).  Saving model ...\n",
      "Validation loss decreased (0.463481 --> 0.461912).  Saving model ...\n",
      "Validation loss decreased (0.461912 --> 0.460345).  Saving model ...\n",
      "Validation loss decreased (0.460345 --> 0.458778).  Saving model ...\n",
      "Validation loss decreased (0.458778 --> 0.457213).  Saving model ...\n",
      "Validation loss decreased (0.457213 --> 0.455653).  Saving model ...\n",
      "Validation loss decreased (0.455653 --> 0.454120).  Saving model ...\n",
      "Epoch: 350 \tTraining Loss: 0.517509 \tValidation Loss: 0.452617\n",
      "Validation loss decreased (0.454120 --> 0.452617).  Saving model ...\n",
      "Validation loss decreased (0.452617 --> 0.451112).  Saving model ...\n",
      "Validation loss decreased (0.451112 --> 0.449609).  Saving model ...\n",
      "Validation loss decreased (0.449609 --> 0.448110).  Saving model ...\n",
      "Validation loss decreased (0.448110 --> 0.446612).  Saving model ...\n",
      "Validation loss decreased (0.446612 --> 0.445111).  Saving model ...\n",
      "Validation loss decreased (0.445111 --> 0.443608).  Saving model ...\n",
      "Validation loss decreased (0.443608 --> 0.442104).  Saving model ...\n",
      "Validation loss decreased (0.442104 --> 0.440598).  Saving model ...\n",
      "Validation loss decreased (0.440598 --> 0.439091).  Saving model ...\n",
      "Epoch: 360 \tTraining Loss: 0.494893 \tValidation Loss: 0.437584\n",
      "Validation loss decreased (0.439091 --> 0.437584).  Saving model ...\n",
      "Validation loss decreased (0.437584 --> 0.436074).  Saving model ...\n",
      "Validation loss decreased (0.436074 --> 0.434565).  Saving model ...\n",
      "Validation loss decreased (0.434565 --> 0.433054).  Saving model ...\n",
      "Validation loss decreased (0.433054 --> 0.431545).  Saving model ...\n",
      "Validation loss decreased (0.431545 --> 0.430089).  Saving model ...\n",
      "Validation loss decreased (0.430089 --> 0.428631).  Saving model ...\n",
      "Validation loss decreased (0.428631 --> 0.427170).  Saving model ...\n",
      "Validation loss decreased (0.427170 --> 0.425706).  Saving model ...\n",
      "Validation loss decreased (0.425706 --> 0.424241).  Saving model ...\n",
      "Epoch: 370 \tTraining Loss: 0.482968 \tValidation Loss: 0.422776\n",
      "Validation loss decreased (0.424241 --> 0.422776).  Saving model ...\n",
      "Validation loss decreased (0.422776 --> 0.421307).  Saving model ...\n",
      "Validation loss decreased (0.421307 --> 0.419836).  Saving model ...\n",
      "Validation loss decreased (0.419836 --> 0.418362).  Saving model ...\n",
      "Validation loss decreased (0.418362 --> 0.416886).  Saving model ...\n",
      "Validation loss decreased (0.416886 --> 0.415432).  Saving model ...\n",
      "Validation loss decreased (0.415432 --> 0.414009).  Saving model ...\n",
      "Validation loss decreased (0.414009 --> 0.412585).  Saving model ...\n",
      "Validation loss decreased (0.412585 --> 0.411159).  Saving model ...\n",
      "Validation loss decreased (0.411159 --> 0.409728).  Saving model ...\n",
      "Epoch: 380 \tTraining Loss: 0.461088 \tValidation Loss: 0.408295\n",
      "Validation loss decreased (0.409728 --> 0.408295).  Saving model ...\n",
      "Validation loss decreased (0.408295 --> 0.406861).  Saving model ...\n",
      "Validation loss decreased (0.406861 --> 0.405426).  Saving model ...\n",
      "Validation loss decreased (0.405426 --> 0.403989).  Saving model ...\n",
      "Validation loss decreased (0.403989 --> 0.402552).  Saving model ...\n",
      "Validation loss decreased (0.402552 --> 0.401112).  Saving model ...\n",
      "Validation loss decreased (0.401112 --> 0.399670).  Saving model ...\n",
      "Validation loss decreased (0.399670 --> 0.398225).  Saving model ...\n",
      "Validation loss decreased (0.398225 --> 0.396780).  Saving model ...\n",
      "Validation loss decreased (0.396780 --> 0.395334).  Saving model ...\n",
      "Epoch: 390 \tTraining Loss: 0.455330 \tValidation Loss: 0.393889\n",
      "Validation loss decreased (0.395334 --> 0.393889).  Saving model ...\n",
      "Validation loss decreased (0.393889 --> 0.392439).  Saving model ...\n",
      "Validation loss decreased (0.392439 --> 0.390989).  Saving model ...\n",
      "Validation loss decreased (0.390989 --> 0.389535).  Saving model ...\n",
      "Validation loss decreased (0.389535 --> 0.388077).  Saving model ...\n",
      "Validation loss decreased (0.388077 --> 0.386617).  Saving model ...\n",
      "Validation loss decreased (0.386617 --> 0.385155).  Saving model ...\n",
      "Validation loss decreased (0.385155 --> 0.383690).  Saving model ...\n",
      "Validation loss decreased (0.383690 --> 0.382225).  Saving model ...\n",
      "Validation loss decreased (0.382225 --> 0.380756).  Saving model ...\n",
      "Epoch: 400 \tTraining Loss: 0.429204 \tValidation Loss: 0.379288\n",
      "Validation loss decreased (0.380756 --> 0.379288).  Saving model ...\n",
      "Validation loss decreased (0.379288 --> 0.377820).  Saving model ...\n",
      "Validation loss decreased (0.377820 --> 0.376352).  Saving model ...\n",
      "Validation loss decreased (0.376352 --> 0.374882).  Saving model ...\n",
      "Validation loss decreased (0.374882 --> 0.373409).  Saving model ...\n",
      "Validation loss decreased (0.373409 --> 0.371932).  Saving model ...\n",
      "Validation loss decreased (0.371932 --> 0.370456).  Saving model ...\n",
      "Validation loss decreased (0.370456 --> 0.368979).  Saving model ...\n",
      "Validation loss decreased (0.368979 --> 0.367502).  Saving model ...\n",
      "Validation loss decreased (0.367502 --> 0.366022).  Saving model ...\n",
      "Epoch: 410 \tTraining Loss: 0.403425 \tValidation Loss: 0.364538\n",
      "Validation loss decreased (0.366022 --> 0.364538).  Saving model ...\n",
      "Validation loss decreased (0.364538 --> 0.363057).  Saving model ...\n",
      "Validation loss decreased (0.363057 --> 0.361575).  Saving model ...\n",
      "Validation loss decreased (0.361575 --> 0.360090).  Saving model ...\n",
      "Validation loss decreased (0.360090 --> 0.358607).  Saving model ...\n",
      "Validation loss decreased (0.358607 --> 0.357124).  Saving model ...\n",
      "Validation loss decreased (0.357124 --> 0.355641).  Saving model ...\n",
      "Validation loss decreased (0.355641 --> 0.354159).  Saving model ...\n",
      "Validation loss decreased (0.354159 --> 0.352672).  Saving model ...\n",
      "Validation loss decreased (0.352672 --> 0.351185).  Saving model ...\n",
      "Epoch: 420 \tTraining Loss: 0.387654 \tValidation Loss: 0.349702\n",
      "Validation loss decreased (0.351185 --> 0.349702).  Saving model ...\n",
      "Validation loss decreased (0.349702 --> 0.348218).  Saving model ...\n",
      "Validation loss decreased (0.348218 --> 0.346731).  Saving model ...\n",
      "Validation loss decreased (0.346731 --> 0.345246).  Saving model ...\n",
      "Validation loss decreased (0.345246 --> 0.343758).  Saving model ...\n",
      "Validation loss decreased (0.343758 --> 0.342294).  Saving model ...\n",
      "Validation loss decreased (0.342294 --> 0.340849).  Saving model ...\n",
      "Validation loss decreased (0.340849 --> 0.339397).  Saving model ...\n",
      "Validation loss decreased (0.339397 --> 0.337942).  Saving model ...\n",
      "Validation loss decreased (0.337942 --> 0.336484).  Saving model ...\n",
      "Epoch: 430 \tTraining Loss: 0.357793 \tValidation Loss: 0.335024\n",
      "Validation loss decreased (0.336484 --> 0.335024).  Saving model ...\n",
      "Validation loss decreased (0.335024 --> 0.333563).  Saving model ...\n",
      "Validation loss decreased (0.333563 --> 0.332102).  Saving model ...\n",
      "Validation loss decreased (0.332102 --> 0.330639).  Saving model ...\n",
      "Validation loss decreased (0.330639 --> 0.329176).  Saving model ...\n",
      "Validation loss decreased (0.329176 --> 0.327715).  Saving model ...\n",
      "Validation loss decreased (0.327715 --> 0.326259).  Saving model ...\n",
      "Validation loss decreased (0.326259 --> 0.324802).  Saving model ...\n",
      "Validation loss decreased (0.324802 --> 0.323338).  Saving model ...\n",
      "Validation loss decreased (0.323338 --> 0.321930).  Saving model ...\n",
      "Epoch: 440 \tTraining Loss: 0.338985 \tValidation Loss: 0.320576\n",
      "Validation loss decreased (0.321930 --> 0.320576).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.320576 --> 0.319218).  Saving model ...\n",
      "Validation loss decreased (0.319218 --> 0.317856).  Saving model ...\n",
      "Validation loss decreased (0.317856 --> 0.316493).  Saving model ...\n",
      "Validation loss decreased (0.316493 --> 0.315126).  Saving model ...\n",
      "Validation loss decreased (0.315126 --> 0.313763).  Saving model ...\n",
      "Validation loss decreased (0.313763 --> 0.312431).  Saving model ...\n",
      "Validation loss decreased (0.312431 --> 0.311132).  Saving model ...\n",
      "Validation loss decreased (0.311132 --> 0.309839).  Saving model ...\n",
      "Validation loss decreased (0.309839 --> 0.308547).  Saving model ...\n",
      "Epoch: 450 \tTraining Loss: 0.346954 \tValidation Loss: 0.307257\n",
      "Validation loss decreased (0.308547 --> 0.307257).  Saving model ...\n",
      "Validation loss decreased (0.307257 --> 0.305963).  Saving model ...\n",
      "Validation loss decreased (0.305963 --> 0.304668).  Saving model ...\n",
      "Validation loss decreased (0.304668 --> 0.303373).  Saving model ...\n",
      "Validation loss decreased (0.303373 --> 0.302081).  Saving model ...\n",
      "Validation loss decreased (0.302081 --> 0.300794).  Saving model ...\n",
      "Validation loss decreased (0.300794 --> 0.299503).  Saving model ...\n",
      "Validation loss decreased (0.299503 --> 0.298211).  Saving model ...\n",
      "Validation loss decreased (0.298211 --> 0.296964).  Saving model ...\n",
      "Validation loss decreased (0.296964 --> 0.295720).  Saving model ...\n",
      "Epoch: 460 \tTraining Loss: 0.320985 \tValidation Loss: 0.294479\n",
      "Validation loss decreased (0.295720 --> 0.294479).  Saving model ...\n",
      "Validation loss decreased (0.294479 --> 0.293235).  Saving model ...\n",
      "Validation loss decreased (0.293235 --> 0.291993).  Saving model ...\n",
      "Validation loss decreased (0.291993 --> 0.290754).  Saving model ...\n",
      "Validation loss decreased (0.290754 --> 0.289515).  Saving model ...\n",
      "Validation loss decreased (0.289515 --> 0.288274).  Saving model ...\n",
      "Validation loss decreased (0.288274 --> 0.287033).  Saving model ...\n",
      "Validation loss decreased (0.287033 --> 0.285798).  Saving model ...\n",
      "Validation loss decreased (0.285798 --> 0.284565).  Saving model ...\n",
      "Validation loss decreased (0.284565 --> 0.283332).  Saving model ...\n",
      "Epoch: 470 \tTraining Loss: 0.301856 \tValidation Loss: 0.282104\n",
      "Validation loss decreased (0.283332 --> 0.282104).  Saving model ...\n",
      "Validation loss decreased (0.282104 --> 0.280890).  Saving model ...\n",
      "Validation loss decreased (0.280890 --> 0.279680).  Saving model ...\n",
      "Validation loss decreased (0.279680 --> 0.278473).  Saving model ...\n",
      "Validation loss decreased (0.278473 --> 0.277265).  Saving model ...\n",
      "Validation loss decreased (0.277265 --> 0.276058).  Saving model ...\n",
      "Validation loss decreased (0.276058 --> 0.274850).  Saving model ...\n",
      "Validation loss decreased (0.274850 --> 0.273647).  Saving model ...\n",
      "Validation loss decreased (0.273647 --> 0.272459).  Saving model ...\n",
      "Validation loss decreased (0.272459 --> 0.271300).  Saving model ...\n",
      "Epoch: 480 \tTraining Loss: 0.296304 \tValidation Loss: 0.270141\n",
      "Validation loss decreased (0.271300 --> 0.270141).  Saving model ...\n",
      "Validation loss decreased (0.270141 --> 0.268983).  Saving model ...\n",
      "Validation loss decreased (0.268983 --> 0.267827).  Saving model ...\n",
      "Validation loss decreased (0.267827 --> 0.266667).  Saving model ...\n",
      "Validation loss decreased (0.266667 --> 0.265512).  Saving model ...\n",
      "Validation loss decreased (0.265512 --> 0.264370).  Saving model ...\n",
      "Validation loss decreased (0.264370 --> 0.263231).  Saving model ...\n",
      "Validation loss decreased (0.263231 --> 0.262094).  Saving model ...\n",
      "Validation loss decreased (0.262094 --> 0.260958).  Saving model ...\n",
      "Validation loss decreased (0.260958 --> 0.259826).  Saving model ...\n",
      "Epoch: 490 \tTraining Loss: 0.271454 \tValidation Loss: 0.258706\n",
      "Validation loss decreased (0.259826 --> 0.258706).  Saving model ...\n",
      "Validation loss decreased (0.258706 --> 0.257589).  Saving model ...\n",
      "Validation loss decreased (0.257589 --> 0.256467).  Saving model ...\n",
      "Validation loss decreased (0.256467 --> 0.255344).  Saving model ...\n",
      "Validation loss decreased (0.255344 --> 0.254224).  Saving model ...\n",
      "Validation loss decreased (0.254224 --> 0.253106).  Saving model ...\n",
      "Validation loss decreased (0.253106 --> 0.252001).  Saving model ...\n",
      "Validation loss decreased (0.252001 --> 0.250937).  Saving model ...\n",
      "Validation loss decreased (0.250937 --> 0.249873).  Saving model ...\n",
      "Validation loss decreased (0.249873 --> 0.248808).  Saving model ...\n",
      "Epoch: 500 \tTraining Loss: 0.254528 \tValidation Loss: 0.247741\n",
      "Validation loss decreased (0.248808 --> 0.247741).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "model_A1,out = train_valid(500, trainX,trainY,validX,validY, model_A1, optimizer_scratch, \n",
    "                      criterion_scratch, 'model_A1.pt',freq = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_A1.load_state_dict(torch.load('model_A1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor =  torch.tensor(testX).type('torch.FloatTensor')\n",
    "model_A1.eval()\n",
    "out = model_A1(test_tensor)\n",
    "out = out.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>0.761940</td>\n",
       "      <td>2.354444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>0.775693</td>\n",
       "      <td>2.680556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>0.795029</td>\n",
       "      <td>3.063889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0.816994</td>\n",
       "      <td>2.462778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>0.831210</td>\n",
       "      <td>1.616667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pred    actual\n",
       "826  0.761940  2.354444\n",
       "827  0.775693  2.680556\n",
       "828  0.795029  3.063889\n",
       "829  0.816994  2.462778\n",
       "830  0.831210  1.616667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out = pd.DataFrame()\n",
    "df_out['pred'] = out[:,0]\n",
    "df_out['actual'] = testY[:,0]\n",
    "#df_out.index = ts_data.index[train_percent + valid_percent:len(ts_data)-w-pred_window]\n",
    "\n",
    "df_out.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out['error'] = np.abs(df_out['pred'] - df_out['actual'])\n",
    "df_out['error_n'] = (df_out['error'] - df_out['error'].mean())/df_out['error'].std()\n",
    "df_out.index = ts_data.index[train_percent + valid_percent +w+pred_window-1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "      <th>error</th>\n",
       "      <th>error_n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>0.713803</td>\n",
       "      <td>3.982222</td>\n",
       "      <td>3.268419</td>\n",
       "      <td>6.339405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>0.897285</td>\n",
       "      <td>5.646111</td>\n",
       "      <td>4.748826</td>\n",
       "      <td>9.482074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>0.891247</td>\n",
       "      <td>10.452778</td>\n",
       "      <td>9.561531</td>\n",
       "      <td>19.698676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.926800</td>\n",
       "      <td>4.237778</td>\n",
       "      <td>3.310978</td>\n",
       "      <td>6.429751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>1.026066</td>\n",
       "      <td>3.192222</td>\n",
       "      <td>2.166157</td>\n",
       "      <td>3.999479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>0.775693</td>\n",
       "      <td>2.680556</td>\n",
       "      <td>1.904862</td>\n",
       "      <td>3.444793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>0.795029</td>\n",
       "      <td>3.063889</td>\n",
       "      <td>2.268860</td>\n",
       "      <td>4.217502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred     actual     error    error_n\n",
       "timestamp                                          \n",
       "844        0.713803   3.982222  3.268419   6.339405\n",
       "1208       0.897285   5.646111  4.748826   9.482074\n",
       "1209       0.891247  10.452778  9.561531  19.698676\n",
       "1210       0.926800   4.237778  3.310978   6.429751\n",
       "1211       1.026066   3.192222  2.166157   3.999479\n",
       "1457       0.775693   2.680556  1.904862   3.444793\n",
       "1458       0.795029   3.063889  2.268860   4.217502"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = df_out.loc[df_out['error_n'].abs() > 3]\n",
    "thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = ts_data.loc[df_out.index].loc[ts_data.is_anomaly == 1].index\n",
    "negatives = ts_data.loc[df_out.index].loc[ts_data.is_anomaly == 0].index\n",
    "tp = []\n",
    "fn = []\n",
    "fp = []\n",
    "tn = []\n",
    "for p in positives:\n",
    "    if p in thresh.index:\n",
    "        tp.append(p)\n",
    "    else:\n",
    "        fn.append(p)\n",
    "\n",
    "for n in negatives:\n",
    "    if n in thresh.index:\n",
    "        fp.append(n)\n",
    "    else:\n",
    "        tn.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777777777777778"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = len(tp)/(len(tp)+len(fn))\n",
    "precision = len(tp)/(len(tp)+len(fp))\n",
    "F_score = 2* recall*precision/(recall + precision)\n",
    "F_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
