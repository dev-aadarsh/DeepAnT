{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Training-on-A1-BenchMark-data\" data-toc-modified-id=\"Training-on-A1-BenchMark-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Training on A1 BenchMark data</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt                        \n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sinewave</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.841471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.873736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.902554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.927809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.949402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sinewave\n",
       "time          \n",
       "0     0.841471\n",
       "1     0.873736\n",
       "2     0.902554\n",
       "3     0.927809\n",
       "4     0.949402"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sinewave = pd.read_csv('./sinewave.csv',index_col = 0)\n",
    "sinewave = sinewave.astype('float')\n",
    "plt.plot(sinewave)\n",
    "sinewave.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Hyperparameters\"\"\"\n",
    "w = 2000                 # History window (number of time stamps taken into account) \n",
    "                         # i.e., filter(kernel) size       \n",
    "p_w = 300                # Prediction window (number of time stampes required to be \n",
    "                         # predicted)\n",
    "n_features = 1           # Univariate time series\n",
    "\n",
    "kernel_size = 2          # Size of filter in conv layers\n",
    "num_filt_1 = 32          # Number of filters in first conv layer\n",
    "num_filt_2 = 32          # Number of filters in second conv layer\n",
    "num_nrn_dl = 40          # Number of neurons in dense layer\n",
    "num_nrn_ol = p_w         # Number of neurons in output layer\n",
    "\n",
    "conv_strides = 1\n",
    "pool_size_1 = 2          # Length of window of pooling layer 1\n",
    "pool_size_2 = 2          # Length of window of pooling layer 2\n",
    "pool_strides_1 = 2       # Stride of window of pooling layer 1\n",
    "pool_strides_2 = 2       # Stride of window of pooling layer 2\n",
    "\n",
    "\n",
    "epochs = 30\n",
    "dropout_rate = 0.2       # Dropout rate in the fully connected layer\n",
    "learning_rate = 2e-5\n",
    "anm_det_thr = 0.8        # Threshold for classifying anomaly (0.5~0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subsequences(data):\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for i in range(len(data) - w -p_w):\n",
    "        X.append(data[i:i+w])\n",
    "        Y.append(data[i+w:i+w+p_w])\n",
    "    return np.array(X),np.array(Y)\n",
    "\n",
    "batch_sample, batch_label = get_subsequences(list(sinewave['sinewave']))\n",
    "batch_sample = np.reshape(batch_sample,(batch_sample.shape[0],batch_sample.shape[1],n_features))\n",
    "train_data = (batch_sample,batch_label)\n",
    "loader = torch.utils.data.DataLoader(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv1d(1, 32, kernel_size=(2,), stride=(1,))\n",
      "  (conv2): Conv1d(32, 32, kernel_size=(2,), stride=(1,))\n",
      "  (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (lin1): Linear(in_features=328, out_features=40, bias=True)\n",
      "  (lin2): Linear(in_features=40, out_features=300, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#  CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        ## layers of a CNN\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(1,num_filt_1,kernel_size,conv_strides,padding = 0)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(num_filt_1,num_filt_2,kernel_size,conv_strides,padding = 0)\n",
    "\n",
    "        self.maxpool = nn.MaxPool1d(pool_size_1)\n",
    "        \n",
    "        self.lin1 = nn.Linear(int(0.25* (w-4) * num_filt_2),num_nrn_dl )\n",
    "        self.lin2 = nn.Linear(num_nrn_dl,p_w)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        \n",
    "        #convolution layer 1\n",
    "        x = (F.relu(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "             \n",
    "        #convolution layer 2\n",
    "        x = (F.relu(self.conv2(x)))\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        print(x.shape)\n",
    "        x = x.view(-1,int(0.25* (w-4) * num_filt_2))\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = (F.relu(self.lin1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = (F.relu(self.lin2(x)))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model_scratch = Net()\n",
    "print(model_scratch)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_scratch = nn.L1Loss()\n",
    "optimizer_scratch = optim.Adam(model_scratch.parameters())#, lr=learning_rate)\n",
    "#optimizer_scratch = optim.SGD(model_scratch.parameters(),lr = learning_rate, momentum=0.9,weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, data,target, model, optimizer, criterion):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "\n",
    "    target = torch.tensor(target).type('torch.FloatTensor')\n",
    "    data = np.reshape(data,(data.shape[0],data.shape[2],data.shape[1]))\n",
    "    data = torch.tensor(data).type('torch.FloatTensor')\n",
    "    \n",
    "    train_loss_min = np.Inf\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # training the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "\n",
    "        #print(data.shape)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss = loss.item()\n",
    "\n",
    "        if(epoch%5 == 0):\n",
    "            print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "                epoch, \n",
    "                train_loss,\n",
    "                ))\n",
    "\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 0.622603\n",
      "Epoch: 10 \tTraining Loss: 0.606197\n",
      "Epoch: 15 \tTraining Loss: 0.589282\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-276-55f47d4f2c10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model_scratch = train(100, batch_sample,batch_label, model_scratch, optimizer_scratch, \n\u001b[1;32m----> 2\u001b[1;33m                       criterion_scratch)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-275-0e5edebae950>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(n_epochs, data, target, model, optimizer, criterion)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_scratch = train(100, batch_sample,batch_label, model_scratch, optimizer_scratch, \n",
    "                      criterion_scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_seq = 1\n",
    "\n",
    "def generate_test_seq(data, n_test_seq,seed = 0):\n",
    "    np.random.seed(0)\n",
    "    rand_idx = np.random.randint(0,len(data) - n_test_seq * w - n_test_seq * p_w)\n",
    "    test_seq = np.array(data[rand_idx:rand_idx + n_test_seq * w +  n_test_seq * p_w])\n",
    "    batch_test_seq, batch_test_label = list(), list()\n",
    "    ix = rand_idx\n",
    "    for i in range(n_test_seq):\n",
    "        seq_x = data[ix : ix+w],\n",
    "        seq_y = data[ix+w : ix+w+p_w]\n",
    "        ix = ix+w+p_w\n",
    "        batch_test_seq.append(seq_x)\n",
    "        batch_test_label.append(seq_y)\n",
    "    return np.array(batch_test_seq), np.array(batch_test_label)\n",
    "\n",
    "batch_test_seq, batch_test_label = generate_test_seq(list(sinewave['sinewave']), n_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model,data,target):\n",
    "    target = torch.tensor(target).type('torch.FloatTensor')\n",
    "    #data = np.reshape(data,(data.shape[0],data.shape[2],data.shape[1]))\n",
    "    data = torch.tensor(data).type('torch.FloatTensor')\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    output = model(data)\n",
    "    loss = criterion_scratch(output, target)\n",
    "    loss_val = loss.item()\n",
    "    print('Testing Loss ',loss_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Loss  0.3913981318473816\n"
     ]
    }
   ],
   "source": [
    "test_model(model_scratch,batch_test_seq,batch_test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on A1 BenchMark data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>is_anomaly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.265278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.100833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.147778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.053889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.051944</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              value  is_anomaly\n",
       "timestamp                      \n",
       "1          1.265278           0\n",
       "2          1.100833           0\n",
       "3          1.147778           0\n",
       "4          1.053889           0\n",
       "5          1.051944           0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data = pd.read_csv('./A1Benchmark/real_60.csv',index_col = 0)\n",
    "#ts_data = ts_data.astype('float')\n",
    "ts_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_anomaly</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            value\n",
       "is_anomaly       \n",
       "0            1445\n",
       "1              16"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data[['is_anomaly','value']].groupby('is_anomaly').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1461, 2)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percent = int(0.3*len(ts_data))\n",
    "valid_percent = int(0.1*len(ts_data))\n",
    "test_percent = int(0.6*len(ts_data))\n",
    "\n",
    "train_data = list(ts_data.iloc[:train_percent,0])\n",
    "valid_data = list(ts_data.iloc[train_percent:train_percent+valid_percent,0])\n",
    "test_data = list(ts_data.iloc[train_percent+valid_percent:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 45\n",
    "pred_window = 1\n",
    "filter1_size = 128\n",
    "filter2_size = 32\n",
    "kernel_size = 2\n",
    "stride = 1\n",
    "pool_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_subsequences(data):\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for i in range(len(data) - w -pred_window):\n",
    "        X.append(data[i:i+w])\n",
    "        Y.append(data[i+w:i+w+pred_window])\n",
    "    return np.array(X),np.array(Y)\n",
    "\n",
    "trainX,trainY = get_subsequences(train_data)\n",
    "trainX = np.reshape(trainX,(trainX.shape[0],1,trainX.shape[1]))\n",
    "\n",
    "validX,validY = get_subsequences(valid_data)\n",
    "validX = np.reshape(validX,(validX.shape[0],1,validX.shape[1]))\n",
    "\n",
    "testX,testY = get_subsequences(test_data)\n",
    "testX = np.reshape(testX,(testX.shape[0],1,testX.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        ## layers of a CNN\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(1,filter1_size,kernel_size,stride,padding = 0)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(filter1_size,filter2_size,kernel_size,stride,padding = 0)\n",
    "\n",
    "        self.maxpool = nn.MaxPool1d(pool_size)\n",
    "        \n",
    "        self.dim1 = int(0.5*(0.5*(w-1)-1)) * filter2_size\n",
    "        \n",
    "        self.lin1 = nn.Linear(self.dim1,pred_window )\n",
    "        #self.lin2 = nn.Linear(1000,pred_window)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        \n",
    "        #convolution layer 1\n",
    "        x = (F.relu(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        #print(x.shape)\n",
    "        #x = self.dropout(x)\n",
    "\n",
    "\n",
    "             \n",
    "        #convolution layer 2\n",
    "        x = (F.relu(self.conv2(x)))\n",
    "        x = self.maxpool(x)\n",
    "        #x = self.dropout(x)\n",
    "\n",
    "        #print(x.shape)\n",
    "\n",
    "\n",
    "        #print(x.shape)\n",
    "        #print(int(0.25* (w) * filter2_size))\n",
    "        x = x.view(-1,self.dim1)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.lin1(x)\n",
    "        #x = self.dropout(x)\n",
    "        #x = self.lin2(x)\n",
    "\n",
    "        \n",
    "        return x\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv1d(1, 128, kernel_size=(2,), stride=(1,))\n",
      "  (conv2): Conv1d(128, 32, kernel_size=(2,), stride=(1,))\n",
      "  (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (lin1): Linear(in_features=320, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_A1 = Net()\n",
    "print(model_A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_scratch = nn.L1Loss()\n",
    "optimizer_scratch = optim.Adam(model_A1.parameters(), lr = 1e-5,weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid(n_epochs, trainX,trainY, validX,validY,model, optimizer, criterion,save_path,freq = 5):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "\n",
    "    target_train = torch.tensor(trainY).type('torch.FloatTensor')\n",
    "    data_train = torch.tensor(trainX).type('torch.FloatTensor')\n",
    "    \n",
    "    target_valid = torch.tensor(validY).type('torch.FloatTensor')\n",
    "    data_valid = torch.tensor(validX).type('torch.FloatTensor')\n",
    "    \n",
    "    train_loss_min = np.Inf\n",
    "    valid_loss_min = np.Inf\n",
    "    last_valid_loss= 0\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        \n",
    "        ###################\n",
    "        # training the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "\n",
    "        #print(data.shape)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data_train)\n",
    "        loss = criterion(output, target_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss = loss.item()\n",
    "        \n",
    "        ###################\n",
    "        # Validation #\n",
    "        ###################\n",
    "        model.eval()\n",
    "        output_valid = model(data_valid)\n",
    "        \n",
    "        loss_valid = criterion(output_valid, target_valid)\n",
    "        valid_loss = loss_valid.item()\n",
    "        if(valid_loss == last_valid_loss):\n",
    "            print('problem')\n",
    "            \n",
    "        last_valid_loss = valid_loss\n",
    "        if(epoch%freq == 0):\n",
    "            print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "                epoch, \n",
    "                train_loss,\n",
    "                valid_loss\n",
    "                ))\n",
    "            \n",
    "        if valid_loss < valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    return model,output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.199891).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.160171 \tValidation Loss: 0.200192\n",
      "Epoch: 20 \tTraining Loss: 0.159312 \tValidation Loss: 0.200439\n",
      "Epoch: 30 \tTraining Loss: 0.165244 \tValidation Loss: 0.200615\n",
      "Epoch: 40 \tTraining Loss: 0.164555 \tValidation Loss: 0.200792\n",
      "Epoch: 50 \tTraining Loss: 0.167510 \tValidation Loss: 0.200920\n",
      "Epoch: 60 \tTraining Loss: 0.174983 \tValidation Loss: 0.200940\n",
      "Epoch: 70 \tTraining Loss: 0.171367 \tValidation Loss: 0.200916\n",
      "Epoch: 80 \tTraining Loss: 0.169199 \tValidation Loss: 0.200847\n",
      "Epoch: 90 \tTraining Loss: 0.162067 \tValidation Loss: 0.200852\n",
      "Epoch: 100 \tTraining Loss: 0.163939 \tValidation Loss: 0.200860\n",
      "Epoch: 110 \tTraining Loss: 0.174090 \tValidation Loss: 0.200779\n",
      "Epoch: 120 \tTraining Loss: 0.169917 \tValidation Loss: 0.200720\n",
      "Epoch: 130 \tTraining Loss: 0.173761 \tValidation Loss: 0.200570\n",
      "Epoch: 140 \tTraining Loss: 0.163403 \tValidation Loss: 0.200352\n",
      "Epoch: 150 \tTraining Loss: 0.164011 \tValidation Loss: 0.200166\n",
      "Epoch: 160 \tTraining Loss: 0.166584 \tValidation Loss: 0.199946\n",
      "Validation loss decreased (0.199891 --> 0.199884).  Saving model ...\n",
      "Validation loss decreased (0.199884 --> 0.199868).  Saving model ...\n",
      "Validation loss decreased (0.199868 --> 0.199851).  Saving model ...\n",
      "Validation loss decreased (0.199851 --> 0.199832).  Saving model ...\n",
      "Validation loss decreased (0.199832 --> 0.199813).  Saving model ...\n",
      "Validation loss decreased (0.199813 --> 0.199792).  Saving model ...\n",
      "Epoch: 170 \tTraining Loss: 0.168809 \tValidation Loss: 0.199767\n",
      "Validation loss decreased (0.199792 --> 0.199767).  Saving model ...\n",
      "Validation loss decreased (0.199767 --> 0.199744).  Saving model ...\n",
      "Validation loss decreased (0.199744 --> 0.199725).  Saving model ...\n",
      "Validation loss decreased (0.199725 --> 0.199703).  Saving model ...\n",
      "Validation loss decreased (0.199703 --> 0.199682).  Saving model ...\n",
      "Validation loss decreased (0.199682 --> 0.199661).  Saving model ...\n",
      "Validation loss decreased (0.199661 --> 0.199640).  Saving model ...\n",
      "Validation loss decreased (0.199640 --> 0.199621).  Saving model ...\n",
      "Validation loss decreased (0.199621 --> 0.199603).  Saving model ...\n",
      "Validation loss decreased (0.199603 --> 0.199578).  Saving model ...\n",
      "Epoch: 180 \tTraining Loss: 0.166823 \tValidation Loss: 0.199548\n",
      "Validation loss decreased (0.199578 --> 0.199548).  Saving model ...\n",
      "Validation loss decreased (0.199548 --> 0.199521).  Saving model ...\n",
      "Validation loss decreased (0.199521 --> 0.199500).  Saving model ...\n",
      "Validation loss decreased (0.199500 --> 0.199490).  Saving model ...\n",
      "Validation loss decreased (0.199490 --> 0.199474).  Saving model ...\n",
      "Validation loss decreased (0.199474 --> 0.199448).  Saving model ...\n",
      "Validation loss decreased (0.199448 --> 0.199415).  Saving model ...\n",
      "Validation loss decreased (0.199415 --> 0.199390).  Saving model ...\n",
      "Validation loss decreased (0.199390 --> 0.199359).  Saving model ...\n",
      "Validation loss decreased (0.199359 --> 0.199335).  Saving model ...\n",
      "Epoch: 190 \tTraining Loss: 0.165855 \tValidation Loss: 0.199315\n",
      "Validation loss decreased (0.199335 --> 0.199315).  Saving model ...\n",
      "Validation loss decreased (0.199315 --> 0.199300).  Saving model ...\n",
      "Validation loss decreased (0.199300 --> 0.199290).  Saving model ...\n",
      "Validation loss decreased (0.199290 --> 0.199284).  Saving model ...\n",
      "Validation loss decreased (0.199284 --> 0.199282).  Saving model ...\n",
      "Validation loss decreased (0.199282 --> 0.199280).  Saving model ...\n",
      "Validation loss decreased (0.199280 --> 0.199277).  Saving model ...\n",
      "Validation loss decreased (0.199277 --> 0.199271).  Saving model ...\n",
      "Epoch: 200 \tTraining Loss: 0.169128 \tValidation Loss: 0.199262\n",
      "Validation loss decreased (0.199271 --> 0.199262).  Saving model ...\n",
      "Validation loss decreased (0.199262 --> 0.199254).  Saving model ...\n",
      "Validation loss decreased (0.199254 --> 0.199240).  Saving model ...\n",
      "Validation loss decreased (0.199240 --> 0.199218).  Saving model ...\n",
      "Validation loss decreased (0.199218 --> 0.199197).  Saving model ...\n",
      "Validation loss decreased (0.199197 --> 0.199180).  Saving model ...\n",
      "Validation loss decreased (0.199180 --> 0.199162).  Saving model ...\n",
      "Validation loss decreased (0.199162 --> 0.199148).  Saving model ...\n",
      "Validation loss decreased (0.199148 --> 0.199128).  Saving model ...\n",
      "Validation loss decreased (0.199128 --> 0.199109).  Saving model ...\n",
      "Epoch: 210 \tTraining Loss: 0.175555 \tValidation Loss: 0.199093\n",
      "Validation loss decreased (0.199109 --> 0.199093).  Saving model ...\n",
      "Validation loss decreased (0.199093 --> 0.199079).  Saving model ...\n",
      "Validation loss decreased (0.199079 --> 0.199062).  Saving model ...\n",
      "Validation loss decreased (0.199062 --> 0.199044).  Saving model ...\n",
      "Validation loss decreased (0.199044 --> 0.199030).  Saving model ...\n",
      "Validation loss decreased (0.199030 --> 0.199015).  Saving model ...\n",
      "Validation loss decreased (0.199015 --> 0.199001).  Saving model ...\n",
      "Validation loss decreased (0.199001 --> 0.198988).  Saving model ...\n",
      "Validation loss decreased (0.198988 --> 0.198974).  Saving model ...\n",
      "Validation loss decreased (0.198974 --> 0.198949).  Saving model ...\n",
      "Epoch: 220 \tTraining Loss: 0.160824 \tValidation Loss: 0.198929\n",
      "Validation loss decreased (0.198949 --> 0.198929).  Saving model ...\n",
      "Validation loss decreased (0.198929 --> 0.198901).  Saving model ...\n",
      "Validation loss decreased (0.198901 --> 0.198877).  Saving model ...\n",
      "Validation loss decreased (0.198877 --> 0.198851).  Saving model ...\n",
      "Validation loss decreased (0.198851 --> 0.198824).  Saving model ...\n",
      "Validation loss decreased (0.198824 --> 0.198794).  Saving model ...\n",
      "Validation loss decreased (0.198794 --> 0.198758).  Saving model ...\n",
      "Validation loss decreased (0.198758 --> 0.198727).  Saving model ...\n",
      "Validation loss decreased (0.198727 --> 0.198698).  Saving model ...\n",
      "Validation loss decreased (0.198698 --> 0.198671).  Saving model ...\n",
      "Epoch: 230 \tTraining Loss: 0.156892 \tValidation Loss: 0.198637\n",
      "Validation loss decreased (0.198671 --> 0.198637).  Saving model ...\n",
      "Validation loss decreased (0.198637 --> 0.198607).  Saving model ...\n",
      "Validation loss decreased (0.198607 --> 0.198578).  Saving model ...\n",
      "Validation loss decreased (0.198578 --> 0.198545).  Saving model ...\n",
      "Validation loss decreased (0.198545 --> 0.198511).  Saving model ...\n",
      "Validation loss decreased (0.198511 --> 0.198477).  Saving model ...\n",
      "Validation loss decreased (0.198477 --> 0.198451).  Saving model ...\n",
      "Validation loss decreased (0.198451 --> 0.198424).  Saving model ...\n",
      "Validation loss decreased (0.198424 --> 0.198393).  Saving model ...\n",
      "Validation loss decreased (0.198393 --> 0.198354).  Saving model ...\n",
      "Epoch: 240 \tTraining Loss: 0.167137 \tValidation Loss: 0.198320\n",
      "Validation loss decreased (0.198354 --> 0.198320).  Saving model ...\n",
      "Validation loss decreased (0.198320 --> 0.198282).  Saving model ...\n",
      "Validation loss decreased (0.198282 --> 0.198249).  Saving model ...\n",
      "Validation loss decreased (0.198249 --> 0.198221).  Saving model ...\n",
      "Validation loss decreased (0.198221 --> 0.198189).  Saving model ...\n",
      "Validation loss decreased (0.198189 --> 0.198156).  Saving model ...\n",
      "Validation loss decreased (0.198156 --> 0.198121).  Saving model ...\n",
      "Validation loss decreased (0.198121 --> 0.198076).  Saving model ...\n",
      "Validation loss decreased (0.198076 --> 0.198030).  Saving model ...\n",
      "Validation loss decreased (0.198030 --> 0.197977).  Saving model ...\n",
      "Epoch: 250 \tTraining Loss: 0.164428 \tValidation Loss: 0.197918\n",
      "Validation loss decreased (0.197977 --> 0.197918).  Saving model ...\n",
      "Validation loss decreased (0.197918 --> 0.197864).  Saving model ...\n",
      "Validation loss decreased (0.197864 --> 0.197809).  Saving model ...\n",
      "Validation loss decreased (0.197809 --> 0.197752).  Saving model ...\n",
      "Validation loss decreased (0.197752 --> 0.197693).  Saving model ...\n",
      "Validation loss decreased (0.197693 --> 0.197632).  Saving model ...\n",
      "Validation loss decreased (0.197632 --> 0.197576).  Saving model ...\n",
      "Validation loss decreased (0.197576 --> 0.197516).  Saving model ...\n",
      "Validation loss decreased (0.197516 --> 0.197457).  Saving model ...\n",
      "Validation loss decreased (0.197457 --> 0.197399).  Saving model ...\n",
      "Epoch: 260 \tTraining Loss: 0.176778 \tValidation Loss: 0.197339\n",
      "Validation loss decreased (0.197399 --> 0.197339).  Saving model ...\n",
      "Validation loss decreased (0.197339 --> 0.197287).  Saving model ...\n",
      "Validation loss decreased (0.197287 --> 0.197239).  Saving model ...\n",
      "Validation loss decreased (0.197239 --> 0.197191).  Saving model ...\n",
      "Validation loss decreased (0.197191 --> 0.197151).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.197151 --> 0.197113).  Saving model ...\n",
      "Validation loss decreased (0.197113 --> 0.197078).  Saving model ...\n",
      "Validation loss decreased (0.197078 --> 0.197045).  Saving model ...\n",
      "Validation loss decreased (0.197045 --> 0.197012).  Saving model ...\n",
      "Validation loss decreased (0.197012 --> 0.196983).  Saving model ...\n",
      "Epoch: 270 \tTraining Loss: 0.165181 \tValidation Loss: 0.196946\n",
      "Validation loss decreased (0.196983 --> 0.196946).  Saving model ...\n",
      "Validation loss decreased (0.196946 --> 0.196907).  Saving model ...\n",
      "Validation loss decreased (0.196907 --> 0.196865).  Saving model ...\n",
      "Validation loss decreased (0.196865 --> 0.196819).  Saving model ...\n",
      "Validation loss decreased (0.196819 --> 0.196787).  Saving model ...\n",
      "Validation loss decreased (0.196787 --> 0.196751).  Saving model ...\n",
      "Validation loss decreased (0.196751 --> 0.196718).  Saving model ...\n",
      "Validation loss decreased (0.196718 --> 0.196694).  Saving model ...\n",
      "Validation loss decreased (0.196694 --> 0.196671).  Saving model ...\n",
      "Validation loss decreased (0.196671 --> 0.196644).  Saving model ...\n",
      "Epoch: 280 \tTraining Loss: 0.166001 \tValidation Loss: 0.196615\n",
      "Validation loss decreased (0.196644 --> 0.196615).  Saving model ...\n",
      "Validation loss decreased (0.196615 --> 0.196584).  Saving model ...\n",
      "Validation loss decreased (0.196584 --> 0.196551).  Saving model ...\n",
      "Validation loss decreased (0.196551 --> 0.196525).  Saving model ...\n",
      "Validation loss decreased (0.196525 --> 0.196501).  Saving model ...\n",
      "Validation loss decreased (0.196501 --> 0.196473).  Saving model ...\n",
      "Validation loss decreased (0.196473 --> 0.196440).  Saving model ...\n",
      "Validation loss decreased (0.196440 --> 0.196405).  Saving model ...\n",
      "Validation loss decreased (0.196405 --> 0.196373).  Saving model ...\n",
      "Validation loss decreased (0.196373 --> 0.196344).  Saving model ...\n",
      "Epoch: 290 \tTraining Loss: 0.159584 \tValidation Loss: 0.196314\n",
      "Validation loss decreased (0.196344 --> 0.196314).  Saving model ...\n",
      "Validation loss decreased (0.196314 --> 0.196287).  Saving model ...\n",
      "Validation loss decreased (0.196287 --> 0.196260).  Saving model ...\n",
      "Validation loss decreased (0.196260 --> 0.196240).  Saving model ...\n",
      "Validation loss decreased (0.196240 --> 0.196215).  Saving model ...\n",
      "Validation loss decreased (0.196215 --> 0.196190).  Saving model ...\n",
      "Validation loss decreased (0.196190 --> 0.196165).  Saving model ...\n",
      "Validation loss decreased (0.196165 --> 0.196138).  Saving model ...\n",
      "Validation loss decreased (0.196138 --> 0.196103).  Saving model ...\n",
      "Validation loss decreased (0.196103 --> 0.196078).  Saving model ...\n",
      "Epoch: 300 \tTraining Loss: 0.164152 \tValidation Loss: 0.196055\n",
      "Validation loss decreased (0.196078 --> 0.196055).  Saving model ...\n",
      "Validation loss decreased (0.196055 --> 0.196033).  Saving model ...\n",
      "Validation loss decreased (0.196033 --> 0.196014).  Saving model ...\n",
      "Validation loss decreased (0.196014 --> 0.195988).  Saving model ...\n",
      "Validation loss decreased (0.195988 --> 0.195958).  Saving model ...\n",
      "Validation loss decreased (0.195958 --> 0.195930).  Saving model ...\n",
      "Validation loss decreased (0.195930 --> 0.195903).  Saving model ...\n",
      "Validation loss decreased (0.195903 --> 0.195869).  Saving model ...\n",
      "Validation loss decreased (0.195869 --> 0.195835).  Saving model ...\n",
      "Validation loss decreased (0.195835 --> 0.195797).  Saving model ...\n",
      "Epoch: 310 \tTraining Loss: 0.156286 \tValidation Loss: 0.195762\n",
      "Validation loss decreased (0.195797 --> 0.195762).  Saving model ...\n",
      "Validation loss decreased (0.195762 --> 0.195734).  Saving model ...\n",
      "Validation loss decreased (0.195734 --> 0.195710).  Saving model ...\n",
      "Validation loss decreased (0.195710 --> 0.195679).  Saving model ...\n",
      "Validation loss decreased (0.195679 --> 0.195648).  Saving model ...\n",
      "Validation loss decreased (0.195648 --> 0.195623).  Saving model ...\n",
      "Validation loss decreased (0.195623 --> 0.195604).  Saving model ...\n",
      "Validation loss decreased (0.195604 --> 0.195585).  Saving model ...\n",
      "Validation loss decreased (0.195585 --> 0.195568).  Saving model ...\n",
      "Validation loss decreased (0.195568 --> 0.195552).  Saving model ...\n",
      "Epoch: 320 \tTraining Loss: 0.157317 \tValidation Loss: 0.195527\n",
      "Validation loss decreased (0.195552 --> 0.195527).  Saving model ...\n",
      "Validation loss decreased (0.195527 --> 0.195496).  Saving model ...\n",
      "Validation loss decreased (0.195496 --> 0.195462).  Saving model ...\n",
      "Validation loss decreased (0.195462 --> 0.195429).  Saving model ...\n",
      "Validation loss decreased (0.195429 --> 0.195400).  Saving model ...\n",
      "Validation loss decreased (0.195400 --> 0.195372).  Saving model ...\n",
      "Validation loss decreased (0.195372 --> 0.195352).  Saving model ...\n",
      "Validation loss decreased (0.195352 --> 0.195328).  Saving model ...\n",
      "Validation loss decreased (0.195328 --> 0.195297).  Saving model ...\n",
      "Validation loss decreased (0.195297 --> 0.195259).  Saving model ...\n",
      "Epoch: 330 \tTraining Loss: 0.163208 \tValidation Loss: 0.195217\n",
      "Validation loss decreased (0.195259 --> 0.195217).  Saving model ...\n",
      "Validation loss decreased (0.195217 --> 0.195181).  Saving model ...\n",
      "Validation loss decreased (0.195181 --> 0.195145).  Saving model ...\n",
      "Validation loss decreased (0.195145 --> 0.195107).  Saving model ...\n",
      "Validation loss decreased (0.195107 --> 0.195071).  Saving model ...\n",
      "Validation loss decreased (0.195071 --> 0.195032).  Saving model ...\n",
      "Validation loss decreased (0.195032 --> 0.194999).  Saving model ...\n",
      "Validation loss decreased (0.194999 --> 0.194954).  Saving model ...\n",
      "Validation loss decreased (0.194954 --> 0.194907).  Saving model ...\n",
      "Validation loss decreased (0.194907 --> 0.194858).  Saving model ...\n",
      "Epoch: 340 \tTraining Loss: 0.178909 \tValidation Loss: 0.194820\n",
      "Validation loss decreased (0.194858 --> 0.194820).  Saving model ...\n",
      "Validation loss decreased (0.194820 --> 0.194778).  Saving model ...\n",
      "Validation loss decreased (0.194778 --> 0.194741).  Saving model ...\n",
      "Validation loss decreased (0.194741 --> 0.194697).  Saving model ...\n",
      "Validation loss decreased (0.194697 --> 0.194652).  Saving model ...\n",
      "Validation loss decreased (0.194652 --> 0.194606).  Saving model ...\n",
      "Validation loss decreased (0.194606 --> 0.194565).  Saving model ...\n",
      "Validation loss decreased (0.194565 --> 0.194527).  Saving model ...\n",
      "Validation loss decreased (0.194527 --> 0.194499).  Saving model ...\n",
      "Validation loss decreased (0.194499 --> 0.194465).  Saving model ...\n",
      "Epoch: 350 \tTraining Loss: 0.170113 \tValidation Loss: 0.194428\n",
      "Validation loss decreased (0.194465 --> 0.194428).  Saving model ...\n",
      "Validation loss decreased (0.194428 --> 0.194386).  Saving model ...\n",
      "Validation loss decreased (0.194386 --> 0.194343).  Saving model ...\n",
      "Validation loss decreased (0.194343 --> 0.194299).  Saving model ...\n",
      "Validation loss decreased (0.194299 --> 0.194256).  Saving model ...\n",
      "Validation loss decreased (0.194256 --> 0.194214).  Saving model ...\n",
      "Validation loss decreased (0.194214 --> 0.194183).  Saving model ...\n",
      "Validation loss decreased (0.194183 --> 0.194157).  Saving model ...\n",
      "Validation loss decreased (0.194157 --> 0.194133).  Saving model ...\n",
      "Validation loss decreased (0.194133 --> 0.194115).  Saving model ...\n",
      "Epoch: 360 \tTraining Loss: 0.157129 \tValidation Loss: 0.194099\n",
      "Validation loss decreased (0.194115 --> 0.194099).  Saving model ...\n",
      "Validation loss decreased (0.194099 --> 0.194088).  Saving model ...\n",
      "Validation loss decreased (0.194088 --> 0.194078).  Saving model ...\n",
      "Validation loss decreased (0.194078 --> 0.194063).  Saving model ...\n",
      "Validation loss decreased (0.194063 --> 0.194052).  Saving model ...\n",
      "Validation loss decreased (0.194052 --> 0.194040).  Saving model ...\n",
      "Validation loss decreased (0.194040 --> 0.194036).  Saving model ...\n",
      "Validation loss decreased (0.194036 --> 0.194030).  Saving model ...\n",
      "Epoch: 370 \tTraining Loss: 0.155542 \tValidation Loss: 0.194038\n",
      "Epoch: 380 \tTraining Loss: 0.163320 \tValidation Loss: 0.194068\n",
      "Validation loss decreased (0.194030 --> 0.194030).  Saving model ...\n",
      "Validation loss decreased (0.194030 --> 0.194013).  Saving model ...\n",
      "Validation loss decreased (0.194013 --> 0.194004).  Saving model ...\n",
      "Validation loss decreased (0.194004 --> 0.193996).  Saving model ...\n",
      "Validation loss decreased (0.193996 --> 0.193981).  Saving model ...\n",
      "Validation loss decreased (0.193981 --> 0.193969).  Saving model ...\n",
      "Validation loss decreased (0.193969 --> 0.193960).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 390 \tTraining Loss: 0.158186 \tValidation Loss: 0.193937\n",
      "Validation loss decreased (0.193960 --> 0.193937).  Saving model ...\n",
      "Validation loss decreased (0.193937 --> 0.193917).  Saving model ...\n",
      "Validation loss decreased (0.193917 --> 0.193900).  Saving model ...\n",
      "Validation loss decreased (0.193900 --> 0.193875).  Saving model ...\n",
      "Validation loss decreased (0.193875 --> 0.193853).  Saving model ...\n",
      "Validation loss decreased (0.193853 --> 0.193832).  Saving model ...\n",
      "Validation loss decreased (0.193832 --> 0.193819).  Saving model ...\n",
      "Validation loss decreased (0.193819 --> 0.193791).  Saving model ...\n",
      "Validation loss decreased (0.193791 --> 0.193761).  Saving model ...\n",
      "Validation loss decreased (0.193761 --> 0.193728).  Saving model ...\n",
      "Epoch: 400 \tTraining Loss: 0.165481 \tValidation Loss: 0.193692\n",
      "Validation loss decreased (0.193728 --> 0.193692).  Saving model ...\n",
      "Validation loss decreased (0.193692 --> 0.193652).  Saving model ...\n",
      "Validation loss decreased (0.193652 --> 0.193624).  Saving model ...\n",
      "Validation loss decreased (0.193624 --> 0.193603).  Saving model ...\n",
      "Validation loss decreased (0.193603 --> 0.193573).  Saving model ...\n",
      "Validation loss decreased (0.193573 --> 0.193543).  Saving model ...\n",
      "Validation loss decreased (0.193543 --> 0.193518).  Saving model ...\n",
      "Validation loss decreased (0.193518 --> 0.193485).  Saving model ...\n",
      "Validation loss decreased (0.193485 --> 0.193460).  Saving model ...\n",
      "Validation loss decreased (0.193460 --> 0.193432).  Saving model ...\n",
      "Epoch: 410 \tTraining Loss: 0.162829 \tValidation Loss: 0.193397\n",
      "Validation loss decreased (0.193432 --> 0.193397).  Saving model ...\n",
      "Validation loss decreased (0.193397 --> 0.193367).  Saving model ...\n",
      "Validation loss decreased (0.193367 --> 0.193338).  Saving model ...\n",
      "Validation loss decreased (0.193338 --> 0.193302).  Saving model ...\n",
      "Validation loss decreased (0.193302 --> 0.193266).  Saving model ...\n",
      "Validation loss decreased (0.193266 --> 0.193222).  Saving model ...\n",
      "Validation loss decreased (0.193222 --> 0.193174).  Saving model ...\n",
      "Validation loss decreased (0.193174 --> 0.193141).  Saving model ...\n",
      "Validation loss decreased (0.193141 --> 0.193106).  Saving model ...\n",
      "Validation loss decreased (0.193106 --> 0.193071).  Saving model ...\n",
      "Epoch: 420 \tTraining Loss: 0.149853 \tValidation Loss: 0.193042\n",
      "Validation loss decreased (0.193071 --> 0.193042).  Saving model ...\n",
      "Validation loss decreased (0.193042 --> 0.193038).  Saving model ...\n",
      "Validation loss decreased (0.193038 --> 0.193009).  Saving model ...\n",
      "Validation loss decreased (0.193009 --> 0.192984).  Saving model ...\n",
      "Validation loss decreased (0.192984 --> 0.192966).  Saving model ...\n",
      "Validation loss decreased (0.192966 --> 0.192948).  Saving model ...\n",
      "Validation loss decreased (0.192948 --> 0.192932).  Saving model ...\n",
      "Validation loss decreased (0.192932 --> 0.192925).  Saving model ...\n",
      "Validation loss decreased (0.192925 --> 0.192914).  Saving model ...\n",
      "Validation loss decreased (0.192914 --> 0.192906).  Saving model ...\n",
      "Epoch: 430 \tTraining Loss: 0.162535 \tValidation Loss: 0.192904\n",
      "Validation loss decreased (0.192906 --> 0.192904).  Saving model ...\n",
      "Validation loss decreased (0.192904 --> 0.192900).  Saving model ...\n",
      "Validation loss decreased (0.192900 --> 0.192894).  Saving model ...\n",
      "Validation loss decreased (0.192894 --> 0.192887).  Saving model ...\n",
      "Validation loss decreased (0.192887 --> 0.192873).  Saving model ...\n",
      "Validation loss decreased (0.192873 --> 0.192852).  Saving model ...\n",
      "Validation loss decreased (0.192852 --> 0.192829).  Saving model ...\n",
      "Validation loss decreased (0.192829 --> 0.192810).  Saving model ...\n",
      "Validation loss decreased (0.192810 --> 0.192781).  Saving model ...\n",
      "Validation loss decreased (0.192781 --> 0.192751).  Saving model ...\n",
      "Epoch: 440 \tTraining Loss: 0.162368 \tValidation Loss: 0.192724\n",
      "Validation loss decreased (0.192751 --> 0.192724).  Saving model ...\n",
      "Validation loss decreased (0.192724 --> 0.192691).  Saving model ...\n",
      "Validation loss decreased (0.192691 --> 0.192657).  Saving model ...\n",
      "Validation loss decreased (0.192657 --> 0.192626).  Saving model ...\n",
      "Validation loss decreased (0.192626 --> 0.192594).  Saving model ...\n",
      "Validation loss decreased (0.192594 --> 0.192551).  Saving model ...\n",
      "Validation loss decreased (0.192551 --> 0.192514).  Saving model ...\n",
      "Validation loss decreased (0.192514 --> 0.192474).  Saving model ...\n",
      "Validation loss decreased (0.192474 --> 0.192437).  Saving model ...\n",
      "Validation loss decreased (0.192437 --> 0.192400).  Saving model ...\n",
      "Epoch: 450 \tTraining Loss: 0.164333 \tValidation Loss: 0.192358\n",
      "Validation loss decreased (0.192400 --> 0.192358).  Saving model ...\n",
      "Validation loss decreased (0.192358 --> 0.192315).  Saving model ...\n",
      "Validation loss decreased (0.192315 --> 0.192270).  Saving model ...\n",
      "Validation loss decreased (0.192270 --> 0.192227).  Saving model ...\n",
      "Validation loss decreased (0.192227 --> 0.192192).  Saving model ...\n",
      "Validation loss decreased (0.192192 --> 0.192157).  Saving model ...\n",
      "Validation loss decreased (0.192157 --> 0.192125).  Saving model ...\n",
      "Validation loss decreased (0.192125 --> 0.192083).  Saving model ...\n",
      "Validation loss decreased (0.192083 --> 0.192044).  Saving model ...\n",
      "Validation loss decreased (0.192044 --> 0.192015).  Saving model ...\n",
      "Epoch: 460 \tTraining Loss: 0.173543 \tValidation Loss: 0.191987\n",
      "Validation loss decreased (0.192015 --> 0.191987).  Saving model ...\n",
      "Validation loss decreased (0.191987 --> 0.191959).  Saving model ...\n",
      "Validation loss decreased (0.191959 --> 0.191929).  Saving model ...\n",
      "Validation loss decreased (0.191929 --> 0.191898).  Saving model ...\n",
      "Validation loss decreased (0.191898 --> 0.191854).  Saving model ...\n",
      "Validation loss decreased (0.191854 --> 0.191796).  Saving model ...\n",
      "Validation loss decreased (0.191796 --> 0.191744).  Saving model ...\n",
      "Validation loss decreased (0.191744 --> 0.191690).  Saving model ...\n",
      "Validation loss decreased (0.191690 --> 0.191647).  Saving model ...\n",
      "Validation loss decreased (0.191647 --> 0.191599).  Saving model ...\n",
      "Epoch: 470 \tTraining Loss: 0.160768 \tValidation Loss: 0.191551\n",
      "Validation loss decreased (0.191599 --> 0.191551).  Saving model ...\n",
      "Validation loss decreased (0.191551 --> 0.191497).  Saving model ...\n",
      "Validation loss decreased (0.191497 --> 0.191447).  Saving model ...\n",
      "Validation loss decreased (0.191447 --> 0.191399).  Saving model ...\n",
      "Validation loss decreased (0.191399 --> 0.191350).  Saving model ...\n",
      "Validation loss decreased (0.191350 --> 0.191309).  Saving model ...\n",
      "Validation loss decreased (0.191309 --> 0.191264).  Saving model ...\n",
      "Validation loss decreased (0.191264 --> 0.191227).  Saving model ...\n",
      "Validation loss decreased (0.191227 --> 0.191177).  Saving model ...\n",
      "Validation loss decreased (0.191177 --> 0.191137).  Saving model ...\n",
      "Epoch: 480 \tTraining Loss: 0.162974 \tValidation Loss: 0.191094\n",
      "Validation loss decreased (0.191137 --> 0.191094).  Saving model ...\n",
      "Validation loss decreased (0.191094 --> 0.191043).  Saving model ...\n",
      "Validation loss decreased (0.191043 --> 0.190994).  Saving model ...\n",
      "Validation loss decreased (0.190994 --> 0.190951).  Saving model ...\n",
      "Validation loss decreased (0.190951 --> 0.190905).  Saving model ...\n",
      "Validation loss decreased (0.190905 --> 0.190862).  Saving model ...\n",
      "Validation loss decreased (0.190862 --> 0.190822).  Saving model ...\n",
      "Validation loss decreased (0.190822 --> 0.190782).  Saving model ...\n",
      "Validation loss decreased (0.190782 --> 0.190747).  Saving model ...\n",
      "Validation loss decreased (0.190747 --> 0.190709).  Saving model ...\n",
      "Epoch: 490 \tTraining Loss: 0.156015 \tValidation Loss: 0.190682\n",
      "Validation loss decreased (0.190709 --> 0.190682).  Saving model ...\n",
      "Validation loss decreased (0.190682 --> 0.190655).  Saving model ...\n",
      "Validation loss decreased (0.190655 --> 0.190624).  Saving model ...\n",
      "Validation loss decreased (0.190624 --> 0.190588).  Saving model ...\n",
      "Validation loss decreased (0.190588 --> 0.190548).  Saving model ...\n",
      "Validation loss decreased (0.190548 --> 0.190515).  Saving model ...\n",
      "Validation loss decreased (0.190515 --> 0.190473).  Saving model ...\n",
      "Validation loss decreased (0.190473 --> 0.190434).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.190434 --> 0.190398).  Saving model ...\n",
      "Validation loss decreased (0.190398 --> 0.190359).  Saving model ...\n",
      "Epoch: 500 \tTraining Loss: 0.152464 \tValidation Loss: 0.190322\n",
      "Validation loss decreased (0.190359 --> 0.190322).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "model_A1,out = train_valid(500, trainX,trainY,validX,validY, model_A1, optimizer_scratch, \n",
    "                      criterion_scratch, 'model_A1.pt',freq = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_A1.load_state_dict(torch.load('model_A1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor =  torch.tensor(testX).type('torch.FloatTensor')\n",
    "model_A1.eval()\n",
    "out = model_A1(test_tensor)\n",
    "out = out.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>0.991928</td>\n",
       "      <td>2.354444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>1.026948</td>\n",
       "      <td>2.680556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>1.042136</td>\n",
       "      <td>3.063889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>1.053000</td>\n",
       "      <td>2.462778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>1.077224</td>\n",
       "      <td>1.616667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pred    actual\n",
       "826  0.991928  2.354444\n",
       "827  1.026948  2.680556\n",
       "828  1.042136  3.063889\n",
       "829  1.053000  2.462778\n",
       "830  1.077224  1.616667"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out = pd.DataFrame()\n",
    "df_out['pred'] = out[:,0]\n",
    "df_out['actual'] = testY[:,0]\n",
    "#df_out.index = ts_data.index[train_percent + valid_percent:len(ts_data)-w-pred_window]\n",
    "\n",
    "df_out.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out['error'] = np.abs(df_out['pred'] - df_out['actual'])\n",
    "df_out['error_n'] = (df_out['error'] - df_out['error'].mean())/df_out['error'].std()\n",
    "df_out.index = ts_data.index[train_percent + valid_percent +w+pred_window-1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "      <th>error</th>\n",
       "      <th>error_n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>0.897088</td>\n",
       "      <td>3.982222</td>\n",
       "      <td>3.085135</td>\n",
       "      <td>6.244851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>1.060543</td>\n",
       "      <td>5.646111</td>\n",
       "      <td>4.585568</td>\n",
       "      <td>9.527006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>1.069160</td>\n",
       "      <td>10.452778</td>\n",
       "      <td>9.383618</td>\n",
       "      <td>20.022597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>1.119900</td>\n",
       "      <td>4.237778</td>\n",
       "      <td>3.117878</td>\n",
       "      <td>6.316476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>1.099984</td>\n",
       "      <td>3.192222</td>\n",
       "      <td>2.092238</td>\n",
       "      <td>4.072920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1.026948</td>\n",
       "      <td>2.680556</td>\n",
       "      <td>1.653607</td>\n",
       "      <td>3.113428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1.042136</td>\n",
       "      <td>3.063889</td>\n",
       "      <td>2.021753</td>\n",
       "      <td>3.918736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred     actual     error    error_n\n",
       "timestamp                                          \n",
       "844        0.897088   3.982222  3.085135   6.244851\n",
       "1208       1.060543   5.646111  4.585568   9.527006\n",
       "1209       1.069160  10.452778  9.383618  20.022597\n",
       "1210       1.119900   4.237778  3.117878   6.316476\n",
       "1211       1.099984   3.192222  2.092238   4.072920\n",
       "1457       1.026948   2.680556  1.653607   3.113428\n",
       "1458       1.042136   3.063889  2.021753   3.918736"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = df_out.loc[df_out['error_n'].abs() > 3]\n",
    "thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = ts_data.loc[df_out.index].loc[ts_data.is_anomaly == 1].index\n",
    "negatives = ts_data.loc[df_out.index].loc[ts_data.is_anomaly == 0].index\n",
    "tp = []\n",
    "fn = []\n",
    "fp = []\n",
    "tn = []\n",
    "for p in positives:\n",
    "    if p in thresh.index:\n",
    "        tp.append(p)\n",
    "    else:\n",
    "        fn.append(p)\n",
    "\n",
    "for n in negatives:\n",
    "    if n in thresh.index:\n",
    "        fp.append(n)\n",
    "    else:\n",
    "        tn.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777777777777778"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = len(tp)/(len(tp)+len(fn))\n",
    "precision = len(tp)/(len(tp)+len(fp))\n",
    "F_score = 2* recall*precision/(recall + precision)\n",
    "F_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
