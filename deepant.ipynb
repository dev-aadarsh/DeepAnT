{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt                        \n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on A1 BenchMark data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>is_anomaly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.265278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.100833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.147778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.053889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.051944</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              value  is_anomaly\n",
       "timestamp                      \n",
       "1          1.265278           0\n",
       "2          1.100833           0\n",
       "3          1.147778           0\n",
       "4          1.053889           0\n",
       "5          1.051944           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load one dataset\n",
    "\n",
    "ts_data = pd.read_csv('./ydata-labeled-time-series-anomalies-v1_0/A1Benchmark/real_60.csv',index_col = 0)\n",
    "#ts_data = ts_data.astype('float')\n",
    "ts_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_anomaly</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            value\n",
       "is_anomaly       \n",
       "0            1445\n",
       "1              16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data[['is_anomaly','value']].groupby('is_anomaly').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1461, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train, test and validation datasets\n",
    "\n",
    "train_percent = int(0.3*len(ts_data))\n",
    "valid_percent = int(0.1*len(ts_data))\n",
    "test_percent = int(0.6*len(ts_data))\n",
    "\n",
    "train_data = list(ts_data.iloc[:train_percent,0])\n",
    "valid_data = list(ts_data.iloc[train_percent:train_percent+valid_percent,0])\n",
    "test_data = list(ts_data.iloc[train_percent+valid_percent:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "\n",
    "w = 45\n",
    "pred_window = 1\n",
    "filter1_size = 128\n",
    "filter2_size = 32\n",
    "kernel_size = 2\n",
    "stride = 1\n",
    "pool_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate subsequences on which we will train\n",
    "\n",
    "def get_subsequences(data):\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for i in range(len(data) - w -pred_window):\n",
    "        X.append(data[i:i+w])\n",
    "        Y.append(data[i+w:i+w+pred_window])\n",
    "    return np.array(X),np.array(Y)\n",
    "\n",
    "trainX,trainY = get_subsequences(train_data)\n",
    "trainX = np.reshape(trainX,(trainX.shape[0],1,trainX.shape[1]))\n",
    "\n",
    "validX,validY = get_subsequences(valid_data)\n",
    "validX = np.reshape(validX,(validX.shape[0],1,validX.shape[1]))\n",
    "\n",
    "testX,testY = get_subsequences(test_data)\n",
    "testX = np.reshape(testX,(testX.shape[0],1,testX.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        ## layers of a CNN\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(1,filter1_size,kernel_size,stride,padding = 0)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(filter1_size,filter2_size,kernel_size,stride,padding = 0)\n",
    "\n",
    "        self.maxpool = nn.MaxPool1d(pool_size)\n",
    "        \n",
    "        self.dim1 = int(0.5*(0.5*(w-1)-1)) * filter2_size\n",
    "        \n",
    "        self.lin1 = nn.Linear(self.dim1,pred_window )\n",
    "        #self.lin2 = nn.Linear(1000,pred_window)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #convolution layer 1\n",
    "        x = (F.relu(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        #print(x.shape)\n",
    "        #x = self.dropout(x)\n",
    "\n",
    "        #convolution layer 2\n",
    "        x = (F.relu(self.conv2(x)))\n",
    "        x = self.maxpool(x)\n",
    "        #x = self.dropout(x)\n",
    "\n",
    "        #print(x.shape)\n",
    "\n",
    "\n",
    "        #print(x.shape)\n",
    "        #print(int(0.25* (w) * filter2_size))\n",
    "        x = x.view(-1,self.dim1)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.lin1(x)\n",
    "        #x = self.dropout(x)\n",
    "        #x = self.lin2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv1d(1, 128, kernel_size=(2,), stride=(1,))\n",
      "  (conv2): Conv1d(128, 32, kernel_size=(2,), stride=(1,))\n",
      "  (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (lin1): Linear(in_features=320, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define CNN model\n",
    "\n",
    "model_A1 = Net()\n",
    "print(model_A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "\n",
    "criterion_scratch = nn.L1Loss()\n",
    "optimizer_scratch = optim.Adam(model_A1.parameters(), lr = 1e-5,weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for training the model (also checks on validation data)\n",
    "\n",
    "def train_valid(n_epochs, trainX,trainY, validX,validY,model, optimizer, criterion,save_path,freq = 5):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "\n",
    "    target_train = torch.tensor(trainY).type('torch.FloatTensor')\n",
    "    data_train = torch.tensor(trainX).type('torch.FloatTensor')\n",
    "    \n",
    "    target_valid = torch.tensor(validY).type('torch.FloatTensor')\n",
    "    data_valid = torch.tensor(validX).type('torch.FloatTensor')\n",
    "    \n",
    "    train_loss_min = np.Inf\n",
    "    valid_loss_min = np.Inf\n",
    "    last_valid_loss= 0\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        \n",
    "        ###################\n",
    "        # training the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "\n",
    "        #print(data.shape)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data_train)\n",
    "        loss = criterion(output, target_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss = loss.item()\n",
    "        \n",
    "        ###################\n",
    "        # Validation #\n",
    "        ###################\n",
    "        model.eval()\n",
    "        output_valid = model(data_valid)\n",
    "        \n",
    "        loss_valid = criterion(output_valid, target_valid)\n",
    "        valid_loss = loss_valid.item()\n",
    "        if(valid_loss == last_valid_loss):\n",
    "            print('problem')\n",
    "            \n",
    "        last_valid_loss = valid_loss\n",
    "        if(epoch%freq == 0):\n",
    "            print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "                epoch, \n",
    "                train_loss,\n",
    "                valid_loss\n",
    "                ))\n",
    "            \n",
    "        if valid_loss < valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "\n",
    "    return model,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.950132).  Saving model ...\n",
      "Validation loss decreased (0.950132 --> 0.948436).  Saving model ...\n",
      "Validation loss decreased (0.948436 --> 0.946736).  Saving model ...\n",
      "Validation loss decreased (0.946736 --> 0.945034).  Saving model ...\n",
      "Validation loss decreased (0.945034 --> 0.943330).  Saving model ...\n",
      "Validation loss decreased (0.943330 --> 0.941626).  Saving model ...\n",
      "Validation loss decreased (0.941626 --> 0.939920).  Saving model ...\n",
      "Validation loss decreased (0.939920 --> 0.938214).  Saving model ...\n",
      "Validation loss decreased (0.938214 --> 0.936505).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.949167 \tValidation Loss: 0.934794\n",
      "Validation loss decreased (0.936505 --> 0.934794).  Saving model ...\n",
      "Validation loss decreased (0.934794 --> 0.933081).  Saving model ...\n",
      "Validation loss decreased (0.933081 --> 0.931362).  Saving model ...\n",
      "Validation loss decreased (0.931362 --> 0.929636).  Saving model ...\n",
      "Validation loss decreased (0.929636 --> 0.927909).  Saving model ...\n",
      "Validation loss decreased (0.927909 --> 0.926180).  Saving model ...\n",
      "Validation loss decreased (0.926180 --> 0.924450).  Saving model ...\n",
      "Validation loss decreased (0.924450 --> 0.922716).  Saving model ...\n",
      "Validation loss decreased (0.922716 --> 0.920983).  Saving model ...\n",
      "Validation loss decreased (0.920983 --> 0.919249).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.927937 \tValidation Loss: 0.917515\n",
      "Validation loss decreased (0.919249 --> 0.917515).  Saving model ...\n",
      "Validation loss decreased (0.917515 --> 0.915780).  Saving model ...\n",
      "Validation loss decreased (0.915780 --> 0.914043).  Saving model ...\n",
      "Validation loss decreased (0.914043 --> 0.912305).  Saving model ...\n",
      "Validation loss decreased (0.912305 --> 0.910567).  Saving model ...\n",
      "Validation loss decreased (0.910567 --> 0.908828).  Saving model ...\n",
      "Validation loss decreased (0.908828 --> 0.907084).  Saving model ...\n",
      "Validation loss decreased (0.907084 --> 0.905339).  Saving model ...\n",
      "Validation loss decreased (0.905339 --> 0.903589).  Saving model ...\n",
      "Validation loss decreased (0.903589 --> 0.901834).  Saving model ...\n",
      "Epoch: 30 \tTraining Loss: 0.916141 \tValidation Loss: 0.900079\n",
      "Validation loss decreased (0.901834 --> 0.900079).  Saving model ...\n",
      "Validation loss decreased (0.900079 --> 0.898323).  Saving model ...\n",
      "Validation loss decreased (0.898323 --> 0.896563).  Saving model ...\n",
      "Validation loss decreased (0.896563 --> 0.894801).  Saving model ...\n",
      "Validation loss decreased (0.894801 --> 0.893034).  Saving model ...\n",
      "Validation loss decreased (0.893034 --> 0.891265).  Saving model ...\n",
      "Validation loss decreased (0.891265 --> 0.889494).  Saving model ...\n",
      "Validation loss decreased (0.889494 --> 0.887721).  Saving model ...\n",
      "Validation loss decreased (0.887721 --> 0.885944).  Saving model ...\n",
      "Validation loss decreased (0.885944 --> 0.884164).  Saving model ...\n",
      "Epoch: 40 \tTraining Loss: 0.893730 \tValidation Loss: 0.882380\n",
      "Validation loss decreased (0.884164 --> 0.882380).  Saving model ...\n",
      "Validation loss decreased (0.882380 --> 0.880589).  Saving model ...\n",
      "Validation loss decreased (0.880589 --> 0.878792).  Saving model ...\n",
      "Validation loss decreased (0.878792 --> 0.876990).  Saving model ...\n",
      "Validation loss decreased (0.876990 --> 0.875183).  Saving model ...\n",
      "Validation loss decreased (0.875183 --> 0.873371).  Saving model ...\n",
      "Validation loss decreased (0.873371 --> 0.871554).  Saving model ...\n",
      "Validation loss decreased (0.871554 --> 0.869732).  Saving model ...\n",
      "Validation loss decreased (0.869732 --> 0.867899).  Saving model ...\n",
      "Validation loss decreased (0.867899 --> 0.866060).  Saving model ...\n",
      "Epoch: 50 \tTraining Loss: 0.871425 \tValidation Loss: 0.864215\n",
      "Validation loss decreased (0.866060 --> 0.864215).  Saving model ...\n",
      "Validation loss decreased (0.864215 --> 0.862364).  Saving model ...\n",
      "Validation loss decreased (0.862364 --> 0.860509).  Saving model ...\n",
      "Validation loss decreased (0.860509 --> 0.858646).  Saving model ...\n",
      "Validation loss decreased (0.858646 --> 0.856775).  Saving model ...\n",
      "Validation loss decreased (0.856775 --> 0.854895).  Saving model ...\n",
      "Validation loss decreased (0.854895 --> 0.853009).  Saving model ...\n",
      "Validation loss decreased (0.853009 --> 0.851113).  Saving model ...\n",
      "Validation loss decreased (0.851113 --> 0.849210).  Saving model ...\n",
      "Validation loss decreased (0.849210 --> 0.847294).  Saving model ...\n",
      "Epoch: 60 \tTraining Loss: 0.861021 \tValidation Loss: 0.845369\n",
      "Validation loss decreased (0.847294 --> 0.845369).  Saving model ...\n",
      "Validation loss decreased (0.845369 --> 0.843437).  Saving model ...\n",
      "Validation loss decreased (0.843437 --> 0.841489).  Saving model ...\n",
      "Validation loss decreased (0.841489 --> 0.839531).  Saving model ...\n",
      "Validation loss decreased (0.839531 --> 0.837565).  Saving model ...\n",
      "Validation loss decreased (0.837565 --> 0.835595).  Saving model ...\n",
      "Validation loss decreased (0.835595 --> 0.833620).  Saving model ...\n",
      "Validation loss decreased (0.833620 --> 0.831640).  Saving model ...\n",
      "Validation loss decreased (0.831640 --> 0.829656).  Saving model ...\n",
      "Validation loss decreased (0.829656 --> 0.827668).  Saving model ...\n",
      "Epoch: 70 \tTraining Loss: 0.842597 \tValidation Loss: 0.825675\n",
      "Validation loss decreased (0.827668 --> 0.825675).  Saving model ...\n",
      "Validation loss decreased (0.825675 --> 0.823675).  Saving model ...\n",
      "Validation loss decreased (0.823675 --> 0.821672).  Saving model ...\n",
      "Validation loss decreased (0.821672 --> 0.819668).  Saving model ...\n",
      "Validation loss decreased (0.819668 --> 0.817660).  Saving model ...\n",
      "Validation loss decreased (0.817660 --> 0.815650).  Saving model ...\n",
      "Validation loss decreased (0.815650 --> 0.813638).  Saving model ...\n",
      "Validation loss decreased (0.813638 --> 0.811623).  Saving model ...\n",
      "Validation loss decreased (0.811623 --> 0.809608).  Saving model ...\n",
      "Validation loss decreased (0.809608 --> 0.807589).  Saving model ...\n",
      "Epoch: 80 \tTraining Loss: 0.823678 \tValidation Loss: 0.805570\n",
      "Validation loss decreased (0.807589 --> 0.805570).  Saving model ...\n",
      "Validation loss decreased (0.805570 --> 0.803552).  Saving model ...\n",
      "Validation loss decreased (0.803552 --> 0.801532).  Saving model ...\n",
      "Validation loss decreased (0.801532 --> 0.799509).  Saving model ...\n",
      "Validation loss decreased (0.799509 --> 0.797487).  Saving model ...\n",
      "Validation loss decreased (0.797487 --> 0.795462).  Saving model ...\n",
      "Validation loss decreased (0.795462 --> 0.793437).  Saving model ...\n",
      "Validation loss decreased (0.793437 --> 0.791411).  Saving model ...\n",
      "Validation loss decreased (0.791411 --> 0.789382).  Saving model ...\n",
      "Validation loss decreased (0.789382 --> 0.787352).  Saving model ...\n",
      "Epoch: 90 \tTraining Loss: 0.801695 \tValidation Loss: 0.785323\n",
      "Validation loss decreased (0.787352 --> 0.785323).  Saving model ...\n",
      "Validation loss decreased (0.785323 --> 0.783292).  Saving model ...\n",
      "Validation loss decreased (0.783292 --> 0.781259).  Saving model ...\n",
      "Validation loss decreased (0.781259 --> 0.779223).  Saving model ...\n",
      "Validation loss decreased (0.779223 --> 0.777189).  Saving model ...\n",
      "Validation loss decreased (0.777189 --> 0.775155).  Saving model ...\n",
      "Validation loss decreased (0.775155 --> 0.773120).  Saving model ...\n",
      "Validation loss decreased (0.773120 --> 0.771085).  Saving model ...\n",
      "Validation loss decreased (0.771085 --> 0.769048).  Saving model ...\n",
      "Validation loss decreased (0.769048 --> 0.767010).  Saving model ...\n",
      "Epoch: 100 \tTraining Loss: 0.786525 \tValidation Loss: 0.764971\n",
      "Validation loss decreased (0.767010 --> 0.764971).  Saving model ...\n",
      "Validation loss decreased (0.764971 --> 0.762932).  Saving model ...\n",
      "Validation loss decreased (0.762932 --> 0.760888).  Saving model ...\n",
      "Validation loss decreased (0.760888 --> 0.758840).  Saving model ...\n",
      "Validation loss decreased (0.758840 --> 0.756790).  Saving model ...\n",
      "Validation loss decreased (0.756790 --> 0.754741).  Saving model ...\n",
      "Validation loss decreased (0.754741 --> 0.752689).  Saving model ...\n",
      "Validation loss decreased (0.752689 --> 0.750636).  Saving model ...\n",
      "Validation loss decreased (0.750636 --> 0.748579).  Saving model ...\n",
      "Validation loss decreased (0.748579 --> 0.746519).  Saving model ...\n",
      "Epoch: 110 \tTraining Loss: 0.762772 \tValidation Loss: 0.744456\n",
      "Validation loss decreased (0.746519 --> 0.744456).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.744456 --> 0.742392).  Saving model ...\n",
      "Validation loss decreased (0.742392 --> 0.740325).  Saving model ...\n",
      "Validation loss decreased (0.740325 --> 0.738253).  Saving model ...\n",
      "Validation loss decreased (0.738253 --> 0.736179).  Saving model ...\n",
      "Validation loss decreased (0.736179 --> 0.734101).  Saving model ...\n",
      "Validation loss decreased (0.734101 --> 0.732022).  Saving model ...\n",
      "Validation loss decreased (0.732022 --> 0.729940).  Saving model ...\n",
      "Validation loss decreased (0.729940 --> 0.727856).  Saving model ...\n",
      "Validation loss decreased (0.727856 --> 0.725773).  Saving model ...\n",
      "Epoch: 120 \tTraining Loss: 0.746423 \tValidation Loss: 0.723686\n",
      "Validation loss decreased (0.725773 --> 0.723686).  Saving model ...\n",
      "Validation loss decreased (0.723686 --> 0.721597).  Saving model ...\n",
      "Validation loss decreased (0.721597 --> 0.719506).  Saving model ...\n",
      "Validation loss decreased (0.719506 --> 0.717414).  Saving model ...\n",
      "Validation loss decreased (0.717414 --> 0.715319).  Saving model ...\n",
      "Validation loss decreased (0.715319 --> 0.713222).  Saving model ...\n",
      "Validation loss decreased (0.713222 --> 0.711122).  Saving model ...\n",
      "Validation loss decreased (0.711122 --> 0.709020).  Saving model ...\n",
      "Validation loss decreased (0.709020 --> 0.706913).  Saving model ...\n",
      "Validation loss decreased (0.706913 --> 0.704802).  Saving model ...\n",
      "Epoch: 130 \tTraining Loss: 0.722166 \tValidation Loss: 0.702687\n",
      "Validation loss decreased (0.704802 --> 0.702687).  Saving model ...\n",
      "Validation loss decreased (0.702687 --> 0.700568).  Saving model ...\n",
      "Validation loss decreased (0.700568 --> 0.698444).  Saving model ...\n",
      "Validation loss decreased (0.698444 --> 0.696317).  Saving model ...\n",
      "Validation loss decreased (0.696317 --> 0.694189).  Saving model ...\n",
      "Validation loss decreased (0.694189 --> 0.692059).  Saving model ...\n",
      "Validation loss decreased (0.692059 --> 0.689925).  Saving model ...\n",
      "Validation loss decreased (0.689925 --> 0.687791).  Saving model ...\n",
      "Validation loss decreased (0.687791 --> 0.685654).  Saving model ...\n",
      "Validation loss decreased (0.685654 --> 0.683513).  Saving model ...\n",
      "Epoch: 140 \tTraining Loss: 0.707452 \tValidation Loss: 0.681369\n",
      "Validation loss decreased (0.683513 --> 0.681369).  Saving model ...\n",
      "Validation loss decreased (0.681369 --> 0.679222).  Saving model ...\n",
      "Validation loss decreased (0.679222 --> 0.677074).  Saving model ...\n",
      "Validation loss decreased (0.677074 --> 0.674919).  Saving model ...\n",
      "Validation loss decreased (0.674919 --> 0.672763).  Saving model ...\n",
      "Validation loss decreased (0.672763 --> 0.670604).  Saving model ...\n",
      "Validation loss decreased (0.670604 --> 0.668442).  Saving model ...\n",
      "Validation loss decreased (0.668442 --> 0.666279).  Saving model ...\n",
      "Validation loss decreased (0.666279 --> 0.664119).  Saving model ...\n",
      "Validation loss decreased (0.664119 --> 0.661964).  Saving model ...\n",
      "Epoch: 150 \tTraining Loss: 0.679622 \tValidation Loss: 0.659807\n",
      "Validation loss decreased (0.661964 --> 0.659807).  Saving model ...\n",
      "Validation loss decreased (0.659807 --> 0.657652).  Saving model ...\n",
      "Validation loss decreased (0.657652 --> 0.655497).  Saving model ...\n",
      "Validation loss decreased (0.655497 --> 0.653346).  Saving model ...\n",
      "Validation loss decreased (0.653346 --> 0.651198).  Saving model ...\n",
      "Validation loss decreased (0.651198 --> 0.649054).  Saving model ...\n",
      "Validation loss decreased (0.649054 --> 0.646910).  Saving model ...\n",
      "Validation loss decreased (0.646910 --> 0.644766).  Saving model ...\n",
      "Validation loss decreased (0.644766 --> 0.642625).  Saving model ...\n",
      "Validation loss decreased (0.642625 --> 0.640484).  Saving model ...\n",
      "Epoch: 160 \tTraining Loss: 0.661582 \tValidation Loss: 0.638343\n",
      "Validation loss decreased (0.640484 --> 0.638343).  Saving model ...\n",
      "Validation loss decreased (0.638343 --> 0.636201).  Saving model ...\n",
      "Validation loss decreased (0.636201 --> 0.634054).  Saving model ...\n",
      "Validation loss decreased (0.634054 --> 0.631910).  Saving model ...\n",
      "Validation loss decreased (0.631910 --> 0.629770).  Saving model ...\n",
      "Validation loss decreased (0.629770 --> 0.627630).  Saving model ...\n",
      "Validation loss decreased (0.627630 --> 0.625487).  Saving model ...\n",
      "Validation loss decreased (0.625487 --> 0.623341).  Saving model ...\n",
      "Validation loss decreased (0.623341 --> 0.621195).  Saving model ...\n",
      "Validation loss decreased (0.621195 --> 0.619050).  Saving model ...\n",
      "Epoch: 170 \tTraining Loss: 0.639938 \tValidation Loss: 0.616903\n",
      "Validation loss decreased (0.619050 --> 0.616903).  Saving model ...\n",
      "Validation loss decreased (0.616903 --> 0.614755).  Saving model ...\n",
      "Validation loss decreased (0.614755 --> 0.612604).  Saving model ...\n",
      "Validation loss decreased (0.612604 --> 0.610453).  Saving model ...\n",
      "Validation loss decreased (0.610453 --> 0.608301).  Saving model ...\n",
      "Validation loss decreased (0.608301 --> 0.606148).  Saving model ...\n",
      "Validation loss decreased (0.606148 --> 0.603991).  Saving model ...\n",
      "Validation loss decreased (0.603991 --> 0.601833).  Saving model ...\n",
      "Validation loss decreased (0.601833 --> 0.599676).  Saving model ...\n",
      "Validation loss decreased (0.599676 --> 0.597516).  Saving model ...\n",
      "Epoch: 180 \tTraining Loss: 0.619634 \tValidation Loss: 0.595353\n",
      "Validation loss decreased (0.597516 --> 0.595353).  Saving model ...\n",
      "Validation loss decreased (0.595353 --> 0.593188).  Saving model ...\n",
      "Validation loss decreased (0.593188 --> 0.591023).  Saving model ...\n",
      "Validation loss decreased (0.591023 --> 0.588855).  Saving model ...\n",
      "Validation loss decreased (0.588855 --> 0.586684).  Saving model ...\n",
      "Validation loss decreased (0.586684 --> 0.584506).  Saving model ...\n",
      "Validation loss decreased (0.584506 --> 0.582325).  Saving model ...\n",
      "Validation loss decreased (0.582325 --> 0.580138).  Saving model ...\n",
      "Validation loss decreased (0.580138 --> 0.577946).  Saving model ...\n",
      "Validation loss decreased (0.577946 --> 0.575750).  Saving model ...\n",
      "Epoch: 190 \tTraining Loss: 0.594482 \tValidation Loss: 0.573550\n",
      "Validation loss decreased (0.575750 --> 0.573550).  Saving model ...\n",
      "Validation loss decreased (0.573550 --> 0.571344).  Saving model ...\n",
      "Validation loss decreased (0.571344 --> 0.569132).  Saving model ...\n",
      "Validation loss decreased (0.569132 --> 0.566918).  Saving model ...\n",
      "Validation loss decreased (0.566918 --> 0.564701).  Saving model ...\n",
      "Validation loss decreased (0.564701 --> 0.562481).  Saving model ...\n",
      "Validation loss decreased (0.562481 --> 0.560257).  Saving model ...\n",
      "Validation loss decreased (0.560257 --> 0.558029).  Saving model ...\n",
      "Validation loss decreased (0.558029 --> 0.555795).  Saving model ...\n",
      "Validation loss decreased (0.555795 --> 0.553555).  Saving model ...\n",
      "Epoch: 200 \tTraining Loss: 0.579035 \tValidation Loss: 0.551311\n",
      "Validation loss decreased (0.553555 --> 0.551311).  Saving model ...\n",
      "Validation loss decreased (0.551311 --> 0.549060).  Saving model ...\n",
      "Validation loss decreased (0.549060 --> 0.546801).  Saving model ...\n",
      "Validation loss decreased (0.546801 --> 0.544536).  Saving model ...\n",
      "Validation loss decreased (0.544536 --> 0.542265).  Saving model ...\n",
      "Validation loss decreased (0.542265 --> 0.539991).  Saving model ...\n",
      "Validation loss decreased (0.539991 --> 0.537710).  Saving model ...\n",
      "Validation loss decreased (0.537710 --> 0.535423).  Saving model ...\n",
      "Validation loss decreased (0.535423 --> 0.533133).  Saving model ...\n",
      "Validation loss decreased (0.533133 --> 0.530837).  Saving model ...\n",
      "Epoch: 210 \tTraining Loss: 0.551722 \tValidation Loss: 0.528537\n",
      "Validation loss decreased (0.530837 --> 0.528537).  Saving model ...\n",
      "Validation loss decreased (0.528537 --> 0.526233).  Saving model ...\n",
      "Validation loss decreased (0.526233 --> 0.523924).  Saving model ...\n",
      "Validation loss decreased (0.523924 --> 0.521611).  Saving model ...\n",
      "Validation loss decreased (0.521611 --> 0.519295).  Saving model ...\n",
      "Validation loss decreased (0.519295 --> 0.516972).  Saving model ...\n",
      "Validation loss decreased (0.516972 --> 0.514648).  Saving model ...\n",
      "Validation loss decreased (0.514648 --> 0.512318).  Saving model ...\n",
      "Validation loss decreased (0.512318 --> 0.509980).  Saving model ...\n",
      "Validation loss decreased (0.509980 --> 0.507639).  Saving model ...\n",
      "Epoch: 220 \tTraining Loss: 0.526045 \tValidation Loss: 0.505292\n",
      "Validation loss decreased (0.507639 --> 0.505292).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.505292 --> 0.502944).  Saving model ...\n",
      "Validation loss decreased (0.502944 --> 0.500589).  Saving model ...\n",
      "Validation loss decreased (0.500589 --> 0.498228).  Saving model ...\n",
      "Validation loss decreased (0.498228 --> 0.495863).  Saving model ...\n",
      "Validation loss decreased (0.495863 --> 0.493496).  Saving model ...\n",
      "Validation loss decreased (0.493496 --> 0.491122).  Saving model ...\n",
      "Validation loss decreased (0.491122 --> 0.488744).  Saving model ...\n",
      "Validation loss decreased (0.488744 --> 0.486356).  Saving model ...\n",
      "Validation loss decreased (0.486356 --> 0.483965).  Saving model ...\n",
      "Epoch: 230 \tTraining Loss: 0.501860 \tValidation Loss: 0.481568\n",
      "Validation loss decreased (0.483965 --> 0.481568).  Saving model ...\n",
      "Validation loss decreased (0.481568 --> 0.479165).  Saving model ...\n",
      "Validation loss decreased (0.479165 --> 0.476757).  Saving model ...\n",
      "Validation loss decreased (0.476757 --> 0.474343).  Saving model ...\n",
      "Validation loss decreased (0.474343 --> 0.471925).  Saving model ...\n",
      "Validation loss decreased (0.471925 --> 0.469503).  Saving model ...\n",
      "Validation loss decreased (0.469503 --> 0.467074).  Saving model ...\n",
      "Validation loss decreased (0.467074 --> 0.464639).  Saving model ...\n",
      "Validation loss decreased (0.464639 --> 0.462200).  Saving model ...\n",
      "Validation loss decreased (0.462200 --> 0.459758).  Saving model ...\n",
      "Epoch: 240 \tTraining Loss: 0.481930 \tValidation Loss: 0.457307\n",
      "Validation loss decreased (0.459758 --> 0.457307).  Saving model ...\n",
      "Validation loss decreased (0.457307 --> 0.454851).  Saving model ...\n",
      "Validation loss decreased (0.454851 --> 0.452392).  Saving model ...\n",
      "Validation loss decreased (0.452392 --> 0.449929).  Saving model ...\n",
      "Validation loss decreased (0.449929 --> 0.447460).  Saving model ...\n",
      "Validation loss decreased (0.447460 --> 0.444986).  Saving model ...\n",
      "Validation loss decreased (0.444986 --> 0.442507).  Saving model ...\n",
      "Validation loss decreased (0.442507 --> 0.440022).  Saving model ...\n",
      "Validation loss decreased (0.440022 --> 0.437534).  Saving model ...\n",
      "Validation loss decreased (0.437534 --> 0.435041).  Saving model ...\n",
      "Epoch: 250 \tTraining Loss: 0.466306 \tValidation Loss: 0.432545\n",
      "Validation loss decreased (0.435041 --> 0.432545).  Saving model ...\n",
      "Validation loss decreased (0.432545 --> 0.430046).  Saving model ...\n",
      "Validation loss decreased (0.430046 --> 0.427544).  Saving model ...\n",
      "Validation loss decreased (0.427544 --> 0.425037).  Saving model ...\n",
      "Validation loss decreased (0.425037 --> 0.422522).  Saving model ...\n",
      "Validation loss decreased (0.422522 --> 0.420003).  Saving model ...\n",
      "Validation loss decreased (0.420003 --> 0.417478).  Saving model ...\n",
      "Validation loss decreased (0.417478 --> 0.414954).  Saving model ...\n",
      "Validation loss decreased (0.414954 --> 0.412426).  Saving model ...\n",
      "Validation loss decreased (0.412426 --> 0.409893).  Saving model ...\n",
      "Epoch: 260 \tTraining Loss: 0.435386 \tValidation Loss: 0.407358\n",
      "Validation loss decreased (0.409893 --> 0.407358).  Saving model ...\n",
      "Validation loss decreased (0.407358 --> 0.404817).  Saving model ...\n",
      "Validation loss decreased (0.404817 --> 0.402274).  Saving model ...\n",
      "Validation loss decreased (0.402274 --> 0.399726).  Saving model ...\n",
      "Validation loss decreased (0.399726 --> 0.397181).  Saving model ...\n",
      "Validation loss decreased (0.397181 --> 0.394631).  Saving model ...\n",
      "Validation loss decreased (0.394631 --> 0.392074).  Saving model ...\n",
      "Validation loss decreased (0.392074 --> 0.389515).  Saving model ...\n",
      "Validation loss decreased (0.389515 --> 0.386948).  Saving model ...\n",
      "Validation loss decreased (0.386948 --> 0.384373).  Saving model ...\n",
      "Epoch: 270 \tTraining Loss: 0.409966 \tValidation Loss: 0.381791\n",
      "Validation loss decreased (0.384373 --> 0.381791).  Saving model ...\n",
      "Validation loss decreased (0.381791 --> 0.379214).  Saving model ...\n",
      "Validation loss decreased (0.379214 --> 0.376628).  Saving model ...\n",
      "Validation loss decreased (0.376628 --> 0.374038).  Saving model ...\n",
      "Validation loss decreased (0.374038 --> 0.371450).  Saving model ...\n",
      "Validation loss decreased (0.371450 --> 0.368855).  Saving model ...\n",
      "Validation loss decreased (0.368855 --> 0.366256).  Saving model ...\n",
      "Validation loss decreased (0.366256 --> 0.363649).  Saving model ...\n",
      "Validation loss decreased (0.363649 --> 0.361040).  Saving model ...\n",
      "Validation loss decreased (0.361040 --> 0.358436).  Saving model ...\n",
      "Epoch: 280 \tTraining Loss: 0.389522 \tValidation Loss: 0.355829\n",
      "Validation loss decreased (0.358436 --> 0.355829).  Saving model ...\n",
      "Validation loss decreased (0.355829 --> 0.353295).  Saving model ...\n",
      "Validation loss decreased (0.353295 --> 0.350763).  Saving model ...\n",
      "Validation loss decreased (0.350763 --> 0.348226).  Saving model ...\n",
      "Validation loss decreased (0.348226 --> 0.345686).  Saving model ...\n",
      "Validation loss decreased (0.345686 --> 0.343142).  Saving model ...\n",
      "Validation loss decreased (0.343142 --> 0.340596).  Saving model ...\n",
      "Validation loss decreased (0.340596 --> 0.338042).  Saving model ...\n",
      "Validation loss decreased (0.338042 --> 0.335488).  Saving model ...\n",
      "Validation loss decreased (0.335488 --> 0.332994).  Saving model ...\n",
      "Epoch: 290 \tTraining Loss: 0.367365 \tValidation Loss: 0.330502\n",
      "Validation loss decreased (0.332994 --> 0.330502).  Saving model ...\n",
      "Validation loss decreased (0.330502 --> 0.328018).  Saving model ...\n",
      "Validation loss decreased (0.328018 --> 0.325534).  Saving model ...\n",
      "Validation loss decreased (0.325534 --> 0.323046).  Saving model ...\n",
      "Validation loss decreased (0.323046 --> 0.320566).  Saving model ...\n",
      "Validation loss decreased (0.320566 --> 0.318081).  Saving model ...\n",
      "Validation loss decreased (0.318081 --> 0.315601).  Saving model ...\n",
      "Validation loss decreased (0.315601 --> 0.313122).  Saving model ...\n",
      "Validation loss decreased (0.313122 --> 0.310638).  Saving model ...\n",
      "Validation loss decreased (0.310638 --> 0.308150).  Saving model ...\n",
      "Epoch: 300 \tTraining Loss: 0.341901 \tValidation Loss: 0.305666\n",
      "Validation loss decreased (0.308150 --> 0.305666).  Saving model ...\n",
      "Validation loss decreased (0.305666 --> 0.303170).  Saving model ...\n",
      "Validation loss decreased (0.303170 --> 0.300677).  Saving model ...\n",
      "Validation loss decreased (0.300677 --> 0.298185).  Saving model ...\n",
      "Validation loss decreased (0.298185 --> 0.295694).  Saving model ...\n",
      "Validation loss decreased (0.295694 --> 0.293205).  Saving model ...\n",
      "Validation loss decreased (0.293205 --> 0.290720).  Saving model ...\n",
      "Validation loss decreased (0.290720 --> 0.288239).  Saving model ...\n",
      "Validation loss decreased (0.288239 --> 0.285754).  Saving model ...\n",
      "Validation loss decreased (0.285754 --> 0.283277).  Saving model ...\n",
      "Epoch: 310 \tTraining Loss: 0.327033 \tValidation Loss: 0.280802\n",
      "Validation loss decreased (0.283277 --> 0.280802).  Saving model ...\n",
      "Validation loss decreased (0.280802 --> 0.278335).  Saving model ...\n",
      "Validation loss decreased (0.278335 --> 0.275862).  Saving model ...\n",
      "Validation loss decreased (0.275862 --> 0.273387).  Saving model ...\n",
      "Validation loss decreased (0.273387 --> 0.270949).  Saving model ...\n",
      "Validation loss decreased (0.270949 --> 0.268528).  Saving model ...\n",
      "Validation loss decreased (0.268528 --> 0.266109).  Saving model ...\n",
      "Validation loss decreased (0.266109 --> 0.263684).  Saving model ...\n",
      "Validation loss decreased (0.263684 --> 0.261266).  Saving model ...\n",
      "Validation loss decreased (0.261266 --> 0.258894).  Saving model ...\n",
      "Epoch: 320 \tTraining Loss: 0.297730 \tValidation Loss: 0.256555\n",
      "Validation loss decreased (0.258894 --> 0.256555).  Saving model ...\n",
      "Validation loss decreased (0.256555 --> 0.254219).  Saving model ...\n",
      "Validation loss decreased (0.254219 --> 0.251909).  Saving model ...\n",
      "Validation loss decreased (0.251909 --> 0.249644).  Saving model ...\n",
      "Validation loss decreased (0.249644 --> 0.247388).  Saving model ...\n",
      "Validation loss decreased (0.247388 --> 0.245133).  Saving model ...\n",
      "Validation loss decreased (0.245133 --> 0.242890).  Saving model ...\n",
      "Validation loss decreased (0.242890 --> 0.240709).  Saving model ...\n",
      "Validation loss decreased (0.240709 --> 0.238536).  Saving model ...\n",
      "Validation loss decreased (0.238536 --> 0.236366).  Saving model ...\n",
      "Epoch: 330 \tTraining Loss: 0.280451 \tValidation Loss: 0.234213\n",
      "Validation loss decreased (0.236366 --> 0.234213).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.234213 --> 0.232053).  Saving model ...\n",
      "Validation loss decreased (0.232053 --> 0.229929).  Saving model ...\n",
      "Validation loss decreased (0.229929 --> 0.227866).  Saving model ...\n",
      "Validation loss decreased (0.227866 --> 0.225812).  Saving model ...\n",
      "Validation loss decreased (0.225812 --> 0.223775).  Saving model ...\n",
      "Validation loss decreased (0.223775 --> 0.221740).  Saving model ...\n",
      "Validation loss decreased (0.221740 --> 0.219706).  Saving model ...\n",
      "Validation loss decreased (0.219706 --> 0.217699).  Saving model ...\n",
      "Validation loss decreased (0.217699 --> 0.215743).  Saving model ...\n",
      "Epoch: 340 \tTraining Loss: 0.260589 \tValidation Loss: 0.213817\n",
      "Validation loss decreased (0.215743 --> 0.213817).  Saving model ...\n",
      "Validation loss decreased (0.213817 --> 0.211924).  Saving model ...\n",
      "Validation loss decreased (0.211924 --> 0.210113).  Saving model ...\n",
      "Validation loss decreased (0.210113 --> 0.208317).  Saving model ...\n",
      "Validation loss decreased (0.208317 --> 0.206528).  Saving model ...\n",
      "Validation loss decreased (0.206528 --> 0.204747).  Saving model ...\n",
      "Validation loss decreased (0.204747 --> 0.203032).  Saving model ...\n",
      "Validation loss decreased (0.203032 --> 0.201341).  Saving model ...\n",
      "Validation loss decreased (0.201341 --> 0.199656).  Saving model ...\n",
      "Validation loss decreased (0.199656 --> 0.197965).  Saving model ...\n",
      "Epoch: 350 \tTraining Loss: 0.247618 \tValidation Loss: 0.196315\n",
      "Validation loss decreased (0.197965 --> 0.196315).  Saving model ...\n",
      "Validation loss decreased (0.196315 --> 0.194683).  Saving model ...\n",
      "Validation loss decreased (0.194683 --> 0.193061).  Saving model ...\n",
      "Validation loss decreased (0.193061 --> 0.191488).  Saving model ...\n",
      "Validation loss decreased (0.191488 --> 0.189959).  Saving model ...\n",
      "Validation loss decreased (0.189959 --> 0.188489).  Saving model ...\n",
      "Validation loss decreased (0.188489 --> 0.187084).  Saving model ...\n",
      "Validation loss decreased (0.187084 --> 0.185735).  Saving model ...\n",
      "Validation loss decreased (0.185735 --> 0.184451).  Saving model ...\n",
      "Validation loss decreased (0.184451 --> 0.183214).  Saving model ...\n",
      "Epoch: 360 \tTraining Loss: 0.235563 \tValidation Loss: 0.181991\n",
      "Validation loss decreased (0.183214 --> 0.181991).  Saving model ...\n",
      "Validation loss decreased (0.181991 --> 0.180771).  Saving model ...\n",
      "Validation loss decreased (0.180771 --> 0.179583).  Saving model ...\n",
      "Validation loss decreased (0.179583 --> 0.178428).  Saving model ...\n",
      "Validation loss decreased (0.178428 --> 0.177289).  Saving model ...\n",
      "Validation loss decreased (0.177289 --> 0.176182).  Saving model ...\n",
      "Validation loss decreased (0.176182 --> 0.175146).  Saving model ...\n",
      "Validation loss decreased (0.175146 --> 0.174130).  Saving model ...\n",
      "Validation loss decreased (0.174130 --> 0.173126).  Saving model ...\n",
      "Validation loss decreased (0.173126 --> 0.172155).  Saving model ...\n",
      "Epoch: 370 \tTraining Loss: 0.212537 \tValidation Loss: 0.171226\n",
      "Validation loss decreased (0.172155 --> 0.171226).  Saving model ...\n",
      "Validation loss decreased (0.171226 --> 0.170340).  Saving model ...\n",
      "Validation loss decreased (0.170340 --> 0.169465).  Saving model ...\n",
      "Validation loss decreased (0.169465 --> 0.168592).  Saving model ...\n",
      "Validation loss decreased (0.168592 --> 0.167721).  Saving model ...\n",
      "Validation loss decreased (0.167721 --> 0.166882).  Saving model ...\n",
      "Validation loss decreased (0.166882 --> 0.166097).  Saving model ...\n",
      "Validation loss decreased (0.166097 --> 0.165321).  Saving model ...\n",
      "Validation loss decreased (0.165321 --> 0.164564).  Saving model ...\n",
      "Validation loss decreased (0.164564 --> 0.163863).  Saving model ...\n",
      "Epoch: 380 \tTraining Loss: 0.204502 \tValidation Loss: 0.163154\n",
      "Validation loss decreased (0.163863 --> 0.163154).  Saving model ...\n",
      "Validation loss decreased (0.163154 --> 0.162459).  Saving model ...\n",
      "Validation loss decreased (0.162459 --> 0.161779).  Saving model ...\n",
      "Validation loss decreased (0.161779 --> 0.161110).  Saving model ...\n",
      "Validation loss decreased (0.161110 --> 0.160469).  Saving model ...\n",
      "Validation loss decreased (0.160469 --> 0.159842).  Saving model ...\n",
      "Validation loss decreased (0.159842 --> 0.159254).  Saving model ...\n",
      "Validation loss decreased (0.159254 --> 0.158683).  Saving model ...\n",
      "Validation loss decreased (0.158683 --> 0.158145).  Saving model ...\n",
      "Validation loss decreased (0.158145 --> 0.157619).  Saving model ...\n",
      "Epoch: 390 \tTraining Loss: 0.206341 \tValidation Loss: 0.157093\n",
      "Validation loss decreased (0.157619 --> 0.157093).  Saving model ...\n",
      "Validation loss decreased (0.157093 --> 0.156566).  Saving model ...\n",
      "Validation loss decreased (0.156566 --> 0.156075).  Saving model ...\n",
      "Validation loss decreased (0.156075 --> 0.155614).  Saving model ...\n",
      "Validation loss decreased (0.155614 --> 0.155175).  Saving model ...\n",
      "Validation loss decreased (0.155175 --> 0.154742).  Saving model ...\n",
      "Validation loss decreased (0.154742 --> 0.154305).  Saving model ...\n",
      "Validation loss decreased (0.154305 --> 0.153876).  Saving model ...\n",
      "Validation loss decreased (0.153876 --> 0.153482).  Saving model ...\n",
      "Validation loss decreased (0.153482 --> 0.153112).  Saving model ...\n",
      "Epoch: 400 \tTraining Loss: 0.201705 \tValidation Loss: 0.152776\n",
      "Validation loss decreased (0.153112 --> 0.152776).  Saving model ...\n",
      "Validation loss decreased (0.152776 --> 0.152468).  Saving model ...\n",
      "Validation loss decreased (0.152468 --> 0.152161).  Saving model ...\n",
      "Validation loss decreased (0.152161 --> 0.151856).  Saving model ...\n",
      "Validation loss decreased (0.151856 --> 0.151582).  Saving model ...\n",
      "Validation loss decreased (0.151582 --> 0.151338).  Saving model ...\n",
      "Validation loss decreased (0.151338 --> 0.151118).  Saving model ...\n",
      "Validation loss decreased (0.151118 --> 0.150931).  Saving model ...\n",
      "Validation loss decreased (0.150931 --> 0.150749).  Saving model ...\n",
      "Validation loss decreased (0.150749 --> 0.150569).  Saving model ...\n",
      "Epoch: 410 \tTraining Loss: 0.178211 \tValidation Loss: 0.150417\n",
      "Validation loss decreased (0.150569 --> 0.150417).  Saving model ...\n",
      "Validation loss decreased (0.150417 --> 0.150269).  Saving model ...\n",
      "Validation loss decreased (0.150269 --> 0.150126).  Saving model ...\n",
      "Validation loss decreased (0.150126 --> 0.149981).  Saving model ...\n",
      "Validation loss decreased (0.149981 --> 0.149838).  Saving model ...\n",
      "Validation loss decreased (0.149838 --> 0.149697).  Saving model ...\n",
      "Validation loss decreased (0.149697 --> 0.149558).  Saving model ...\n",
      "Validation loss decreased (0.149558 --> 0.149439).  Saving model ...\n",
      "Validation loss decreased (0.149439 --> 0.149320).  Saving model ...\n",
      "Validation loss decreased (0.149320 --> 0.149202).  Saving model ...\n",
      "Epoch: 420 \tTraining Loss: 0.178216 \tValidation Loss: 0.149084\n",
      "Validation loss decreased (0.149202 --> 0.149084).  Saving model ...\n",
      "Validation loss decreased (0.149084 --> 0.148969).  Saving model ...\n",
      "Validation loss decreased (0.148969 --> 0.148857).  Saving model ...\n",
      "Validation loss decreased (0.148857 --> 0.148743).  Saving model ...\n",
      "Validation loss decreased (0.148743 --> 0.148631).  Saving model ...\n",
      "Validation loss decreased (0.148631 --> 0.148542).  Saving model ...\n",
      "Validation loss decreased (0.148542 --> 0.148454).  Saving model ...\n",
      "Validation loss decreased (0.148454 --> 0.148367).  Saving model ...\n",
      "Validation loss decreased (0.148367 --> 0.148282).  Saving model ...\n",
      "Validation loss decreased (0.148282 --> 0.148200).  Saving model ...\n",
      "Epoch: 430 \tTraining Loss: 0.170852 \tValidation Loss: 0.148120\n",
      "Validation loss decreased (0.148200 --> 0.148120).  Saving model ...\n",
      "Validation loss decreased (0.148120 --> 0.148041).  Saving model ...\n",
      "Validation loss decreased (0.148041 --> 0.147963).  Saving model ...\n",
      "Validation loss decreased (0.147963 --> 0.147885).  Saving model ...\n",
      "Validation loss decreased (0.147885 --> 0.147807).  Saving model ...\n",
      "Validation loss decreased (0.147807 --> 0.147731).  Saving model ...\n",
      "Validation loss decreased (0.147731 --> 0.147656).  Saving model ...\n",
      "Validation loss decreased (0.147656 --> 0.147586).  Saving model ...\n",
      "Validation loss decreased (0.147586 --> 0.147531).  Saving model ...\n",
      "Validation loss decreased (0.147531 --> 0.147476).  Saving model ...\n",
      "Epoch: 440 \tTraining Loss: 0.175683 \tValidation Loss: 0.147422\n",
      "Validation loss decreased (0.147476 --> 0.147422).  Saving model ...\n",
      "Validation loss decreased (0.147422 --> 0.147367).  Saving model ...\n",
      "Validation loss decreased (0.147367 --> 0.147313).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.147313 --> 0.147260).  Saving model ...\n",
      "Validation loss decreased (0.147260 --> 0.147209).  Saving model ...\n",
      "Validation loss decreased (0.147209 --> 0.147158).  Saving model ...\n",
      "Validation loss decreased (0.147158 --> 0.147108).  Saving model ...\n",
      "Validation loss decreased (0.147108 --> 0.147061).  Saving model ...\n",
      "Validation loss decreased (0.147061 --> 0.147014).  Saving model ...\n",
      "Validation loss decreased (0.147014 --> 0.146968).  Saving model ...\n",
      "Epoch: 450 \tTraining Loss: 0.173749 \tValidation Loss: 0.146923\n",
      "Validation loss decreased (0.146968 --> 0.146923).  Saving model ...\n",
      "Validation loss decreased (0.146923 --> 0.146879).  Saving model ...\n",
      "Validation loss decreased (0.146879 --> 0.146834).  Saving model ...\n",
      "Validation loss decreased (0.146834 --> 0.146791).  Saving model ...\n",
      "Validation loss decreased (0.146791 --> 0.146747).  Saving model ...\n",
      "Validation loss decreased (0.146747 --> 0.146704).  Saving model ...\n",
      "Validation loss decreased (0.146704 --> 0.146660).  Saving model ...\n",
      "Validation loss decreased (0.146660 --> 0.146636).  Saving model ...\n",
      "Validation loss decreased (0.146636 --> 0.146622).  Saving model ...\n",
      "Validation loss decreased (0.146622 --> 0.146621).  Saving model ...\n",
      "Epoch: 460 \tTraining Loss: 0.177132 \tValidation Loss: 0.146630\n",
      "Epoch: 470 \tTraining Loss: 0.174544 \tValidation Loss: 0.146810\n",
      "Epoch: 480 \tTraining Loss: 0.178081 \tValidation Loss: 0.146961\n",
      "Epoch: 490 \tTraining Loss: 0.172105 \tValidation Loss: 0.147148\n",
      "Epoch: 500 \tTraining Loss: 0.174198 \tValidation Loss: 0.147497\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "model_A1,out = train_valid(500, trainX,trainY,validX,validY, model_A1, optimizer_scratch, \n",
    "                      criterion_scratch, 'model_A1.pt',freq = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load best model (saved previously during training)\n",
    "\n",
    "model_A1.load_state_dict(torch.load('model_A1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "\n",
    "test_tensor =  torch.tensor(testX).type('torch.FloatTensor')\n",
    "model_A1.eval()\n",
    "out = model_A1(test_tensor)\n",
    "out = out.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>0.941016</td>\n",
       "      <td>2.354444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>0.951111</td>\n",
       "      <td>2.680556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>0.954491</td>\n",
       "      <td>3.063889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0.967551</td>\n",
       "      <td>2.462778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>0.971499</td>\n",
       "      <td>1.616667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pred    actual\n",
       "826  0.941016  2.354444\n",
       "827  0.951111  2.680556\n",
       "828  0.954491  3.063889\n",
       "829  0.967551  2.462778\n",
       "830  0.971499  1.616667"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out = pd.DataFrame()\n",
    "df_out['pred'] = out[:,0]\n",
    "df_out['actual'] = testY[:,0]\n",
    "#df_out.index = ts_data.index[train_percent + valid_percent:len(ts_data)-w-pred_window]\n",
    "\n",
    "df_out.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute error (actual - pred)\n",
    "\n",
    "df_out['error'] = np.abs(df_out['pred'] - df_out['actual'])\n",
    "df_out['error_n'] = (df_out['error'] - df_out['error'].mean())/df_out['error'].std()\n",
    "df_out.index = ts_data.index[train_percent + valid_percent +w+pred_window-1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "      <th>error</th>\n",
       "      <th>error_n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>0.871605</td>\n",
       "      <td>3.982222</td>\n",
       "      <td>3.110617</td>\n",
       "      <td>6.303662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>1.055828</td>\n",
       "      <td>5.646111</td>\n",
       "      <td>4.590283</td>\n",
       "      <td>9.530605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>1.051940</td>\n",
       "      <td>10.452778</td>\n",
       "      <td>9.400838</td>\n",
       "      <td>20.021752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>1.020918</td>\n",
       "      <td>4.237778</td>\n",
       "      <td>3.216860</td>\n",
       "      <td>6.535363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>1.087213</td>\n",
       "      <td>3.192222</td>\n",
       "      <td>2.105010</td>\n",
       "      <td>4.110573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>0.951111</td>\n",
       "      <td>2.680556</td>\n",
       "      <td>1.729444</td>\n",
       "      <td>3.291517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>0.954491</td>\n",
       "      <td>3.063889</td>\n",
       "      <td>2.109398</td>\n",
       "      <td>4.120144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred     actual     error    error_n\n",
       "timestamp                                          \n",
       "844        0.871605   3.982222  3.110617   6.303662\n",
       "1208       1.055828   5.646111  4.590283   9.530605\n",
       "1209       1.051940  10.452778  9.400838  20.021752\n",
       "1210       1.020918   4.237778  3.216860   6.535363\n",
       "1211       1.087213   3.192222  2.105010   4.110573\n",
       "1457       0.951111   2.680556  1.729444   3.291517\n",
       "1458       0.954491   3.063889  2.109398   4.120144"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whether error is more than the threshold\n",
    "\n",
    "thresh = df_out.loc[df_out['error_n'].abs() > 3]\n",
    "thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc TP, FN, FP, TN\n",
    "\n",
    "positives = ts_data.loc[df_out.index].loc[ts_data.is_anomaly == 1].index\n",
    "negatives = ts_data.loc[df_out.index].loc[ts_data.is_anomaly == 0].index\n",
    "tp = []\n",
    "fn = []\n",
    "fp = []\n",
    "tn = []\n",
    "for p in positives:\n",
    "    if p in thresh.index:\n",
    "        tp.append(p)\n",
    "    else:\n",
    "        fn.append(p)\n",
    "\n",
    "for n in negatives:\n",
    "    if n in thresh.index:\n",
    "        fp.append(n)\n",
    "    else:\n",
    "        tn.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777777777777778"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc F-score\n",
    "\n",
    "recall = len(tp)/(len(tp)+len(fn))\n",
    "precision = len(tp)/(len(tp)+len(fp))\n",
    "F_score = 2* recall*precision/(recall + precision)\n",
    "F_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
